{"config":{"indexing":"full","lang":["pt"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":".rst-content > div:first-of-type { display:none } .document{ display: flex; flex-direction: column; align-items:center; height: 100%; width: 100% } .document .section{ display: flex; flex-direction: column; align-items:center; height: 100%; width: 100% } Bem vindo ao Almanaque da Secretaria de Transforma\u00e7\u00e3o Digital RJ Aqui disponibilizamos os diversos estudos e relat\u00f3rios desenvolvidos pela Secretaria para melhor entendimento e dissemina\u00e7\u00e3o de nosso trabalho. Para visualizar o documento, pesquise por palavras-chave ou procure no cat\u00e1logo ao lado pelo nome do relat\u00f3rio ou estudo em quest\u00e3o. Acesse o GitHub para ter acesso a integra de nossos c\u00f3digos: supdados Em caso de d\u00favidas n\u00e3o exite em entrar em contato conosco pelo email supdados@digital.rj.gov.br .","title":"Home"},{"location":"#bem-vindo-ao-almanaque-da-secretaria-de-transformacao-digital-rj","text":"Aqui disponibilizamos os diversos estudos e relat\u00f3rios desenvolvidos pela Secretaria para melhor entendimento e dissemina\u00e7\u00e3o de nosso trabalho. Para visualizar o documento, pesquise por palavras-chave ou procure no cat\u00e1logo ao lado pelo nome do relat\u00f3rio ou estudo em quest\u00e3o. Acesse o GitHub para ter acesso a integra de nossos c\u00f3digos: supdados Em caso de d\u00favidas n\u00e3o exite em entrar em contato conosco pelo email supdados@digital.rj.gov.br .","title":"Bem vindo ao Almanaque da Secretaria de Transforma\u00e7\u00e3o Digital RJ"},{"location":"Relatorios/avaliacaoChatbot/","text":"Modelo de Avalia\u00e7\u00e3o de Chatbot. .rst-content .section .docutils { display: table; } figcaption { font-weight:bold; font-size: 16px; } Autores Beatriz Gomes de Souza Introdu\u00e7\u00e3o Este relat\u00f3rio apresenta a avalia\u00e7\u00e3o de desempenho de um chatbot voltado para a consulta de servi\u00e7os, com o objetivo de verificar sua efic\u00e1cia na compreens\u00e3o das solicita\u00e7\u00f5es dos usu\u00e1rios, precis\u00e3o nas respostas e fluidez na intera\u00e7\u00e3o. A an\u00e1lise abrange tanto m\u00e9tricas quantitativas \u2014 como acur\u00e1cia, precis\u00e3o, recall e F1-score \u2014 quanto aspectos qualitativos relacionados \u00e0 experi\u00eancia do usu\u00e1rio, como a satisfa\u00e7\u00e3o geral com o atendimento. Al\u00e9m disso, s\u00e3o consideradas an\u00e1lises t\u00e9cnicas relacionadas ao modelo de linguagem utilizado, incluindo a qualidade dos embeddings sem\u00e2nticos respons\u00e1veis por mapear as inten\u00e7\u00f5es e varia\u00e7\u00f5es lingu\u00edsticas dos usu\u00e1rios. A partir dos resultados obtidos, o modelo de avalia\u00e7\u00e3o aqui descrito viabiliza oportunidades de aprimoramento do sistema e recomenda\u00e7\u00f5es para futuras atualiza\u00e7\u00f5es do chatbot. Neste momento, o modelo de avalia\u00e7\u00e3o adotado ir\u00e1 desconsiderar as vari\u00e1veis qualitativas tradicionais, como clareza da linguagem e naturalidade da conversa, uma vez que essas dependem da aplica\u00e7\u00e3o de instrumentos espec\u00edficos, como pesquisas de satisfa\u00e7\u00e3o, entrevistas ou testes de usabilidade, os quais n\u00e3o est\u00e3o dispon\u00edveis no presente est\u00e1gio da an\u00e1lise. Assim, a avalia\u00e7\u00e3o qualitativa ser\u00e1 limitada ao feedback espont\u00e2neo fornecido pelos usu\u00e1rios durante o uso do chatbot, registrado no pr\u00f3prio fluxo de intera\u00e7\u00e3o. Para avalia\u00e7\u00e3o do desempenho geral, genericamente, usar-se-\u00e1 as seguintes defini\u00e7\u00f5es: M\u00e9trica O que avalia? Observa\u00e7\u00f5es Acur\u00e1cia Percentual de acertos na identifica\u00e7\u00e3o correta da inten\u00e7\u00e3o Pode mascarar performance se classes forem desbalanceadas Matriz de confus\u00e3o Desempenho de um modelo de classifica\u00e7\u00e3o Quantas previs\u00f5es ele acertou ou errou em compara\u00e7\u00e3o com os valores reais Relev\u00e2ncia Cumprimento da necessidade de informa\u00e7\u00e3o do usu\u00e1rio Realizada a partir da an\u00e1lise dos embeddings Recall Cobertura dos acertos sobre todas as inten\u00e7\u00f5es Baixo recall indica que muitas inten\u00e7\u00f5es reais n\u00e3o foram detectadas Precis\u00e3o Corre\u00e7\u00e3o das inten\u00e7\u00f5es/respostas dadas Alta precis\u00e3o evita respostas incorretas Taxa de fallback Quantas vezes o bot n\u00e3o entendeu Fallback frequente pode indicar falhas no NLP F1 Score M\u00e9dia harm\u00f4nica de precis\u00e3o e recall Boa m\u00e9trica geral de desempenho Feedback do usu\u00e1rio Retorno dado pelo pr\u00f3prio usu\u00e1rio sobre o bot Indica satisfa\u00e7\u00e3o dos usu\u00e1rios do bot Defini\u00e7\u00e3o M\u00e9tricas de C\u00e1lculo Conceitos e Defini\u00e7\u00f5es Fundamentais: Nesta se\u00e7\u00e3o, trataremos de alguns conceitos b\u00e1sicos e fundamentais para compreender a avalia\u00e7\u00e3o de chatbot. INTEN\u00c7\u00c3O : \u00e9 a representa\u00e7\u00e3o da a\u00e7\u00e3o ou objetivo que o usu\u00e1rio deseja realizar ao enviar uma mensagem. \u00c9 a forma como o sistema interpreta o que o usu\u00e1rio quer fazer, independentemente da forma como ele se expressa. Desta forma, a defini\u00e7\u00e3o das vari\u00e1veis e seus resultados s\u00e3o: Acur\u00e1cia : Acur\u00e1cia mede quantas vezes o modelo acertou, considerando todos os casos, tanto positivos quanto negativos. Temos ent\u00e3o que: $ acur\u00e1cia = \\frac{VP+VN}{VP+VN+FP+FN} $ Onde: VP (Verdadeiro Positivo): acertos em casos positivos. VN (Verdadeiro Negativo): acertos em casos negativos. FP (Falso Positivo): falsos positivos (erros do tipo 1). FN (Falso Negativo): falsos negativos (erros do tipo 2). No caso da acur\u00e1cia, se n\u00e3o forem bem definidos os VP, VN, FP, FN, a medida de avalia\u00e7\u00e3o ir\u00e1 alucinar. Para solucionar este problema, utiliza-se a Matriz de Confus\u00e3o como m\u00e9todo a dar suporte no c\u00e1lculo de acur\u00e1cia. a. Matriz de confus\u00e3o: Um chatbot inteligente precisa entender a inten\u00e7\u00e3o do usu\u00e1rio e responder adequadamente. Para saber se ele est\u00e1 fazendo isso bem, usa-se m\u00e9tricas de avalia\u00e7\u00e3o \u2014 e uma das mais importantes \u00e9 a matriz de confus\u00e3o. A matriz de confus\u00e3o \u00e9 uma tabela que compara o que o modelo previu com o que era real. Ela \u00e9 muito usada em classifica\u00e7\u00e3o, como quando um chatbot tenta identificar a inten\u00e7\u00e3o de uma pergunta (\u201cemitir documento\", \"agendar consulta\", \"consulta de rem\u00e9dio\"). Classe Real Positivos Negativos Positivo VP FN Negativo FP VN Desta forma, a diagonal principal VP - VN representa os acerto (o chatbot acertou a inten\u00e7\u00e3o do usu\u00e1rio), enquanto a diagonal de fora FN-FP representa os erros (o chatbot confundiu as inten\u00e7\u00f5es). Recall de classes : Avaliar um chatbot que entende linguagem natural (NLP) n\u00e3o \u00e9 s\u00f3 dizer se ele \"acerta ou erra\". Precisamos saber como ele erra \u2014 e o recall \u00e9 uma m\u00e9trica que responde a uma pergunta muito importante: \u201cQuantos dos casos que deveriam ter sido detectados, ele de fato conseguiu identificar corretamente?\u201d. Logo, o recall se concentra na linha da matriz de confus\u00e3o, ou seja, nos valores reais. Ele mede quantos dos exemplos de uma classe espec\u00edfica foram corretamente identificados. Reutilizando os termos identificados na Matriz de Confus\u00e3o, temos que a f\u00f3rmula final do recall \u00e9 dada por: $ Recall = \\frac{VP}{VP+FN} $ O resultado do recall destaca que o modelo encontrou x% dos casos reais da classe que ele predeterminou a detectar. Logo, 90% de recall implica em dizer que o modelo acertou 90% das vezes e errou 10% das vezes. O recall destaca a relev\u00e2ncia do modelo, uma vez que, recalls altos implicam em modelos que erram pouco. Por\u00e9m, \u00e9 necess\u00e1rio analisar tamb\u00e9m a precis\u00e3o. Precis\u00e3o : A precis\u00e3o \u00e9 uma m\u00e9trica usada para avaliar a performance de modelos de classifica\u00e7\u00e3o, como aqueles usados em sistemas de reconhecimento de inten\u00e7\u00f5es em chatbots. Ela responde \u00e0 seguinte pergunta: \u201cDas previs\u00f5es positivas feitas pelo modelo, quantas estavam corretas?\u201d Ou seja, mede a qualidade dos acertos, e n\u00e3o apenas a quantidade. A f\u00f3rmula da precis\u00e3o \u00e9: $ \\frac{VP}{VP+FP} $ Nessa equa\u00e7\u00e3o, verdadeiros positivos (VP) s\u00e3o os casos em que o modelo previu corretamente a classe positiva, enquanto falsos positivos (FP) s\u00e3o os casos em que o modelo previu positivamente, mas estava errado. Em outras palavras, o modelo disse que era daquela classe, mas n\u00e3o era. Por exemplo, em um chatbot que tenta identificar quando o usu\u00e1rio quer \"falar com um atendente\", a precis\u00e3o indicaria quantas das vezes em que o sistema pensou que o usu\u00e1rio queria um atendente, ele estava certo. Se o chatbot previu 50 frases como \"falar com atendente\", mas apenas 30 estavam realmente corretas, a precis\u00e3o seria: $ Precis\u00e3o = \\frac{30}{30+20} = \\frac{30}{50} = 0.6 = 60\\% $ A interpreta\u00e7\u00e3o do resultado consiste em x% das vezes em que o modelo previu que determinada inten\u00e7\u00e3o estava certa. Ou seja, a cada x previs\u00f5es positivas, y eram equivocadas. A precis\u00e3o nos ajuda a entender o quanto podemos confiar nas decis\u00f5es positivas do modelo. Por\u00e9m, como ela n\u00e3o considera os falsos negativos (casos que deveriam ter sido positivos mas foram ignorados), ela costuma ser analisada em conjunto com o recall, e muitas vezes se usa a m\u00e9trica F1-score para equilibrar ambas. F1 Score : O F1-score \u00e9 uma m\u00e9trica de avalia\u00e7\u00e3o usada em tarefas de classifica\u00e7\u00e3o \u2014 como no funcionamento de chatbots baseados em NLP \u2014 que busca equilibrar duas medidas essenciais: precis\u00e3o e recall. Enquanto a precis\u00e3o mede o quanto das previs\u00f5es positivas estavam corretas, e o recall indica o quanto dos casos relevantes foram encontrados, o F1-score combina ambas em um \u00fanico n\u00famero, permitindo uma vis\u00e3o mais completa da performance do modelo. A f\u00f3rmula do F1-score \u00e9: $ F1-score = 2 * \\frac{precis\u00e3o\\ *\\ recall}{precis\u00e3o\\ +\\ recall} $ Essa \u00e9 a m\u00e9dia harm\u00f4nica entre precis\u00e3o e recall \u2014 uma forma de evitar que o F1-score seja alto se apenas uma das duas m\u00e9tricas for alta e a outra for muito baixa. Em outras palavras, o F1-score penaliza desequil\u00edbrios entre precis\u00e3o e recall, exigindo que ambas estejam razoavelmente boas para que o valor final tamb\u00e9m seja satisfat\u00f3rio. O F1-score varia entre 0 e 1: 1 significa desempenho perfeito: todas as previs\u00f5es relevantes foram feitas corretamente e sem erros. 0 indica falha total: nenhuma previs\u00e3o relevante ou correta foi feita. Valores entre 0,5 e 0,9 indicam n\u00edveis moderados a bons n\u00edveis de desempenho, dependendo do contexto e da aplica\u00e7\u00e3o. O F1-score \u00e9 especialmente \u00fatil quando: H\u00e1 classes desbalanceadas (ou seja, algumas categorias s\u00e3o muito mais frequentes que outras); Erros de falsos positivos e falsos negativos t\u00eam impactos igualmente relevantes; Voc\u00ea precisa avaliar o modelo de forma equilibrada, sem favorecer s\u00f3 recall ou s\u00f3 precis\u00e3o. Em sistemas de chatbots, o F1-score pode mostrar se o modelo est\u00e1 sendo eficiente em identificar inten\u00e7\u00f5es sem errar demais ou sem deixar passar intera\u00e7\u00f5es importantes. Fallback : Em sistemas de chatbots com NLP (Processamento de Linguagem Natural), o termo fallback se refere \u00e0 resposta padr\u00e3o do sistema quando ele n\u00e3o consegue entender ou classificar corretamente a entrada do usu\u00e1rio. \u00c9, essencialmente, um mecanismo de seguran\u00e7a: quando o modelo n\u00e3o tem certeza sobre a inten\u00e7\u00e3o ou a confian\u00e7a da previs\u00e3o \u00e9 muito baixa, ele \"desiste\" de tentar responder de forma espec\u00edfica e ativa uma resposta gen\u00e9rica \u2014 como por exemplo: \u201cDesculpe, n\u00e3o entendi. Pode reformular?\u201d. Do ponto de vista t\u00e9cnico, o fallback \u00e9 ativado com base em limiares de confian\u00e7a (confidence threshold) definidos no modelo de classifica\u00e7\u00e3o. Se a previs\u00e3o da inten\u00e7\u00e3o do usu\u00e1rio n\u00e3o atingir esse limite m\u00ednimo de confian\u00e7a, o chatbot considera que \u00e9 melhor n\u00e3o arriscar uma resposta incorreta e, assim, retorna a resposta fallback. Embora o fallback seja uma prote\u00e7\u00e3o contra erros graves de interpreta\u00e7\u00e3o, ele tamb\u00e9m \u00e9 um sinal de limita\u00e7\u00e3o do modelo. Um n\u00famero alto de fallbacks pode indicar que: O modelo n\u00e3o est\u00e1 entendendo bem o vocabul\u00e1rio dos usu\u00e1rios; As inten\u00e7\u00f5es est\u00e3o mal definidas ou muito parecidas entre si; Os dados de treinamento s\u00e3o insuficientes ou mal distribu\u00eddos; O limiar de confian\u00e7a est\u00e1 muito alto, fazendo o modelo \"desistir\" com facilidade. A an\u00e1lise quantitativa do fallback pode ser feita simplesmente contando a frequ\u00eancia com que ele ocorre durante as intera\u00e7\u00f5es. Uma m\u00e9trica comum \u00e9: $ Taxa de Fallback = \\frac{N\u00famero\\ de\\ respostas\\ fallback}{N\u00famero\\ total\\ de\\ interac\u00f5es} $ Por exemplo, se um chatbot respondeu com fallback em 150 de 1.000 intera\u00e7\u00f5es, a taxa de fallback \u00e9 15%. A interpreta\u00e7\u00e3o do resultado da taxa de fallback depende do contexto. Em geral, uma taxa de fallback abaixo de 5% \u00e9 considerada boa para chatbots bem treinados. Taxas acima de 10% sinalizam que o modelo precisa de ajustes \u2014 seja nos dados, nas inten\u00e7\u00f5es ou nas regras de fallback.Em suma, o fallback \u00e9 um indicativo da robustez e cobertura do modelo. Feedback do usu\u00e1rio : O feedback do usu\u00e1rio \u00e9 uma das formas mais diretas e valiosas de avaliar se o modelo est\u00e1 cumprindo seu papel de forma eficaz. Diferentemente de m\u00e9tricas internas, como acur\u00e1cia ou recall, o feedback representa a percep\u00e7\u00e3o real do usu\u00e1rio sobre a qualidade da intera\u00e7\u00e3o \u2014 e, portanto, oferece uma perspectiva essencial para o aprimoramento cont\u00ednuo do sistema. O feedback pode ser expl\u00edcito, quando o usu\u00e1rio \u00e9 convidado a avaliar a resposta do chatbot (por exemplo, com bot\u00f5es de \ud83d\udc4d/\ud83d\udc4e ou uma escala de satisfa\u00e7\u00e3o), ou impl\u00edcito, quando o sistema infere a satisfa\u00e7\u00e3o com base em comportamentos, como repeti\u00e7\u00e3o da pergunta, abandono da conversa, ou solicita\u00e7\u00e3o direta por atendimento humano. Neste caso, consideramos o caso de avalia\u00e7\u00e3o expl\u00edcita. Esse retorno pode ser classificado, armazenado e analisado por meio de m\u00e9tricas como: $ Taxa\\ de\\ Satisfac\u00e3o = \\frac{N\u00famero\\ de\\ feedbacks\\ positivos}{Total\\ de\\ feedbacks\\ coletados} $ A interpreta\u00e7\u00e3o da taxa de satisfa\u00e7\u00e3o pode ser dada, genericamente, como: Acima de 85%: o chatbot est\u00e1 oferecendo uma experi\u00eancia positiva e confi\u00e1vel para a maioria dos usu\u00e1rios. Entre 60% e 85%: o sistema est\u00e1 funcional, mas h\u00e1 espa\u00e7o para ajustes nas respostas, tom de linguagem ou entendimento das inten\u00e7\u00f5es. Abaixo de 60%: sinal de alerta \u2014 o chatbot est\u00e1 frequentemente falhando em atender \u00e0s expectativas dos usu\u00e1rios. Por fim, vale destacar que a aus\u00eancia de feedback tamb\u00e9m deve ser monitorada. Se poucos usu\u00e1rios interagem com os mecanismos de avalia\u00e7\u00e3o, isso pode indicar que o sistema n\u00e3o est\u00e1 incentivando e facilitando essa intera\u00e7\u00e3o, o que prejudica o processo de melhoria cont\u00ednua. Interpreta\u00e7\u00e3o dos resultados O desempenho geral do chatbot : Para construirmos uma f\u00f3rmula geral de desempenho que venha a refletir todos os aspectos t\u00e9cnicos e de experi\u00eancia do usu\u00e1rio a partir de suas respectivas import\u00e2ncias atribu\u00eddas, teremos definidos, ent\u00e3o: A acur\u00e1cia como a propor\u00e7\u00e3o de classifica\u00e7\u00f5es corretas entre todas as previs\u00f5es F1-score como o equil\u00edbrio entre precis\u00e3o e recall Fallback como o indicador de falha na compreens\u00e3o Feedback do usu\u00e1rio como a avalia\u00e7\u00e3o qualitativa da experi\u00eancia do usu\u00e1rio E, por sua vez, a precis\u00e3o j\u00e1 est\u00e1 contida no F1-score, mas vamos destac\u00e1-la se for necess\u00e1rio ajustar. Sendo assim, a constru\u00e7\u00e3o de uma f\u00f3rmula geral d\u00e1-se por: $ Desempenho\\ Geral = 0.10 * F1score + 0.10 * (1 - Fallback) + 0.10 * Acur\u00e1cia + 0.70 * Feedback $ Onde: F1-score ser\u00e1 uma m\u00e9trica principal, refletindo a qualidade t\u00e9cnica do modelo. Taxa de fallback ser\u00e1 usada como penalidade (quanto mais alto o fallback, menor o desempenho). Acur\u00e1cia \u00e9 utilizada para verificar a propor\u00e7\u00e3o de classifica\u00e7\u00f5es corretas entre todas as previs\u00f5es. Feedback do usu\u00e1rio (de 0 a 1) ter\u00e1 peso 0.70, pois reflete diretamente a percep\u00e7\u00e3o de qualidade. Refer\u00eancias Izbicki, Rafael. Aprendizado de m\u00e1quina : uma abordagem estat\u00edstica [livro eletr\u00f4nico] / Rafael Izbicki, Tiago Mendon\u00e7a dos Santos. -- S\u00e3o Carlos, SP : Rafael Izbicki, 2020.","title":"Modelo de Avalia\u00e7\u00e3o de Chatbot."},{"location":"Relatorios/avaliacaoChatbot/#modelo-de-avaliacao-de-chatbot","text":".rst-content .section .docutils { display: table; } figcaption { font-weight:bold; font-size: 16px; }","title":"Modelo de Avalia\u00e7\u00e3o de Chatbot."},{"location":"Relatorios/avaliacaoChatbot/#autores","text":"Beatriz Gomes de Souza","title":"Autores"},{"location":"Relatorios/avaliacaoChatbot/#introducao","text":"Este relat\u00f3rio apresenta a avalia\u00e7\u00e3o de desempenho de um chatbot voltado para a consulta de servi\u00e7os, com o objetivo de verificar sua efic\u00e1cia na compreens\u00e3o das solicita\u00e7\u00f5es dos usu\u00e1rios, precis\u00e3o nas respostas e fluidez na intera\u00e7\u00e3o. A an\u00e1lise abrange tanto m\u00e9tricas quantitativas \u2014 como acur\u00e1cia, precis\u00e3o, recall e F1-score \u2014 quanto aspectos qualitativos relacionados \u00e0 experi\u00eancia do usu\u00e1rio, como a satisfa\u00e7\u00e3o geral com o atendimento. Al\u00e9m disso, s\u00e3o consideradas an\u00e1lises t\u00e9cnicas relacionadas ao modelo de linguagem utilizado, incluindo a qualidade dos embeddings sem\u00e2nticos respons\u00e1veis por mapear as inten\u00e7\u00f5es e varia\u00e7\u00f5es lingu\u00edsticas dos usu\u00e1rios. A partir dos resultados obtidos, o modelo de avalia\u00e7\u00e3o aqui descrito viabiliza oportunidades de aprimoramento do sistema e recomenda\u00e7\u00f5es para futuras atualiza\u00e7\u00f5es do chatbot. Neste momento, o modelo de avalia\u00e7\u00e3o adotado ir\u00e1 desconsiderar as vari\u00e1veis qualitativas tradicionais, como clareza da linguagem e naturalidade da conversa, uma vez que essas dependem da aplica\u00e7\u00e3o de instrumentos espec\u00edficos, como pesquisas de satisfa\u00e7\u00e3o, entrevistas ou testes de usabilidade, os quais n\u00e3o est\u00e3o dispon\u00edveis no presente est\u00e1gio da an\u00e1lise. Assim, a avalia\u00e7\u00e3o qualitativa ser\u00e1 limitada ao feedback espont\u00e2neo fornecido pelos usu\u00e1rios durante o uso do chatbot, registrado no pr\u00f3prio fluxo de intera\u00e7\u00e3o. Para avalia\u00e7\u00e3o do desempenho geral, genericamente, usar-se-\u00e1 as seguintes defini\u00e7\u00f5es: M\u00e9trica O que avalia? Observa\u00e7\u00f5es Acur\u00e1cia Percentual de acertos na identifica\u00e7\u00e3o correta da inten\u00e7\u00e3o Pode mascarar performance se classes forem desbalanceadas Matriz de confus\u00e3o Desempenho de um modelo de classifica\u00e7\u00e3o Quantas previs\u00f5es ele acertou ou errou em compara\u00e7\u00e3o com os valores reais Relev\u00e2ncia Cumprimento da necessidade de informa\u00e7\u00e3o do usu\u00e1rio Realizada a partir da an\u00e1lise dos embeddings Recall Cobertura dos acertos sobre todas as inten\u00e7\u00f5es Baixo recall indica que muitas inten\u00e7\u00f5es reais n\u00e3o foram detectadas Precis\u00e3o Corre\u00e7\u00e3o das inten\u00e7\u00f5es/respostas dadas Alta precis\u00e3o evita respostas incorretas Taxa de fallback Quantas vezes o bot n\u00e3o entendeu Fallback frequente pode indicar falhas no NLP F1 Score M\u00e9dia harm\u00f4nica de precis\u00e3o e recall Boa m\u00e9trica geral de desempenho Feedback do usu\u00e1rio Retorno dado pelo pr\u00f3prio usu\u00e1rio sobre o bot Indica satisfa\u00e7\u00e3o dos usu\u00e1rios do bot","title":"Introdu\u00e7\u00e3o"},{"location":"Relatorios/avaliacaoChatbot/#definicao-metricas-de-calculo","text":"","title":"Defini\u00e7\u00e3o M\u00e9tricas de C\u00e1lculo"},{"location":"Relatorios/avaliacaoChatbot/#conceitos-e-definicoes-fundamentais","text":"Nesta se\u00e7\u00e3o, trataremos de alguns conceitos b\u00e1sicos e fundamentais para compreender a avalia\u00e7\u00e3o de chatbot.","title":"Conceitos e Defini\u00e7\u00f5es Fundamentais:"},{"location":"Relatorios/avaliacaoChatbot/#intencao","text":"\u00e9 a representa\u00e7\u00e3o da a\u00e7\u00e3o ou objetivo que o usu\u00e1rio deseja realizar ao enviar uma mensagem. \u00c9 a forma como o sistema interpreta o que o usu\u00e1rio quer fazer, independentemente da forma como ele se expressa. Desta forma, a defini\u00e7\u00e3o das vari\u00e1veis e seus resultados s\u00e3o:","title":"INTEN\u00c7\u00c3O:"},{"location":"Relatorios/avaliacaoChatbot/#acuracia","text":"Acur\u00e1cia mede quantas vezes o modelo acertou, considerando todos os casos, tanto positivos quanto negativos. Temos ent\u00e3o que: $ acur\u00e1cia = \\frac{VP+VN}{VP+VN+FP+FN} $ Onde: VP (Verdadeiro Positivo): acertos em casos positivos. VN (Verdadeiro Negativo): acertos em casos negativos. FP (Falso Positivo): falsos positivos (erros do tipo 1). FN (Falso Negativo): falsos negativos (erros do tipo 2). No caso da acur\u00e1cia, se n\u00e3o forem bem definidos os VP, VN, FP, FN, a medida de avalia\u00e7\u00e3o ir\u00e1 alucinar. Para solucionar este problema, utiliza-se a Matriz de Confus\u00e3o como m\u00e9todo a dar suporte no c\u00e1lculo de acur\u00e1cia. a. Matriz de confus\u00e3o: Um chatbot inteligente precisa entender a inten\u00e7\u00e3o do usu\u00e1rio e responder adequadamente. Para saber se ele est\u00e1 fazendo isso bem, usa-se m\u00e9tricas de avalia\u00e7\u00e3o \u2014 e uma das mais importantes \u00e9 a matriz de confus\u00e3o. A matriz de confus\u00e3o \u00e9 uma tabela que compara o que o modelo previu com o que era real. Ela \u00e9 muito usada em classifica\u00e7\u00e3o, como quando um chatbot tenta identificar a inten\u00e7\u00e3o de uma pergunta (\u201cemitir documento\", \"agendar consulta\", \"consulta de rem\u00e9dio\"). Classe Real Positivos Negativos Positivo VP FN Negativo FP VN Desta forma, a diagonal principal VP - VN representa os acerto (o chatbot acertou a inten\u00e7\u00e3o do usu\u00e1rio), enquanto a diagonal de fora FN-FP representa os erros (o chatbot confundiu as inten\u00e7\u00f5es).","title":"Acur\u00e1cia:"},{"location":"Relatorios/avaliacaoChatbot/#recall-de-classes","text":"Avaliar um chatbot que entende linguagem natural (NLP) n\u00e3o \u00e9 s\u00f3 dizer se ele \"acerta ou erra\". Precisamos saber como ele erra \u2014 e o recall \u00e9 uma m\u00e9trica que responde a uma pergunta muito importante: \u201cQuantos dos casos que deveriam ter sido detectados, ele de fato conseguiu identificar corretamente?\u201d. Logo, o recall se concentra na linha da matriz de confus\u00e3o, ou seja, nos valores reais. Ele mede quantos dos exemplos de uma classe espec\u00edfica foram corretamente identificados. Reutilizando os termos identificados na Matriz de Confus\u00e3o, temos que a f\u00f3rmula final do recall \u00e9 dada por: $ Recall = \\frac{VP}{VP+FN} $ O resultado do recall destaca que o modelo encontrou x% dos casos reais da classe que ele predeterminou a detectar. Logo, 90% de recall implica em dizer que o modelo acertou 90% das vezes e errou 10% das vezes. O recall destaca a relev\u00e2ncia do modelo, uma vez que, recalls altos implicam em modelos que erram pouco. Por\u00e9m, \u00e9 necess\u00e1rio analisar tamb\u00e9m a precis\u00e3o.","title":"Recall de classes:"},{"location":"Relatorios/avaliacaoChatbot/#precisao","text":"A precis\u00e3o \u00e9 uma m\u00e9trica usada para avaliar a performance de modelos de classifica\u00e7\u00e3o, como aqueles usados em sistemas de reconhecimento de inten\u00e7\u00f5es em chatbots. Ela responde \u00e0 seguinte pergunta: \u201cDas previs\u00f5es positivas feitas pelo modelo, quantas estavam corretas?\u201d Ou seja, mede a qualidade dos acertos, e n\u00e3o apenas a quantidade. A f\u00f3rmula da precis\u00e3o \u00e9: $ \\frac{VP}{VP+FP} $ Nessa equa\u00e7\u00e3o, verdadeiros positivos (VP) s\u00e3o os casos em que o modelo previu corretamente a classe positiva, enquanto falsos positivos (FP) s\u00e3o os casos em que o modelo previu positivamente, mas estava errado. Em outras palavras, o modelo disse que era daquela classe, mas n\u00e3o era. Por exemplo, em um chatbot que tenta identificar quando o usu\u00e1rio quer \"falar com um atendente\", a precis\u00e3o indicaria quantas das vezes em que o sistema pensou que o usu\u00e1rio queria um atendente, ele estava certo. Se o chatbot previu 50 frases como \"falar com atendente\", mas apenas 30 estavam realmente corretas, a precis\u00e3o seria: $ Precis\u00e3o = \\frac{30}{30+20} = \\frac{30}{50} = 0.6 = 60\\% $ A interpreta\u00e7\u00e3o do resultado consiste em x% das vezes em que o modelo previu que determinada inten\u00e7\u00e3o estava certa. Ou seja, a cada x previs\u00f5es positivas, y eram equivocadas. A precis\u00e3o nos ajuda a entender o quanto podemos confiar nas decis\u00f5es positivas do modelo. Por\u00e9m, como ela n\u00e3o considera os falsos negativos (casos que deveriam ter sido positivos mas foram ignorados), ela costuma ser analisada em conjunto com o recall, e muitas vezes se usa a m\u00e9trica F1-score para equilibrar ambas.","title":"Precis\u00e3o:"},{"location":"Relatorios/avaliacaoChatbot/#f1-score","text":"O F1-score \u00e9 uma m\u00e9trica de avalia\u00e7\u00e3o usada em tarefas de classifica\u00e7\u00e3o \u2014 como no funcionamento de chatbots baseados em NLP \u2014 que busca equilibrar duas medidas essenciais: precis\u00e3o e recall. Enquanto a precis\u00e3o mede o quanto das previs\u00f5es positivas estavam corretas, e o recall indica o quanto dos casos relevantes foram encontrados, o F1-score combina ambas em um \u00fanico n\u00famero, permitindo uma vis\u00e3o mais completa da performance do modelo. A f\u00f3rmula do F1-score \u00e9: $ F1-score = 2 * \\frac{precis\u00e3o\\ *\\ recall}{precis\u00e3o\\ +\\ recall} $ Essa \u00e9 a m\u00e9dia harm\u00f4nica entre precis\u00e3o e recall \u2014 uma forma de evitar que o F1-score seja alto se apenas uma das duas m\u00e9tricas for alta e a outra for muito baixa. Em outras palavras, o F1-score penaliza desequil\u00edbrios entre precis\u00e3o e recall, exigindo que ambas estejam razoavelmente boas para que o valor final tamb\u00e9m seja satisfat\u00f3rio. O F1-score varia entre 0 e 1: 1 significa desempenho perfeito: todas as previs\u00f5es relevantes foram feitas corretamente e sem erros. 0 indica falha total: nenhuma previs\u00e3o relevante ou correta foi feita. Valores entre 0,5 e 0,9 indicam n\u00edveis moderados a bons n\u00edveis de desempenho, dependendo do contexto e da aplica\u00e7\u00e3o. O F1-score \u00e9 especialmente \u00fatil quando: H\u00e1 classes desbalanceadas (ou seja, algumas categorias s\u00e3o muito mais frequentes que outras); Erros de falsos positivos e falsos negativos t\u00eam impactos igualmente relevantes; Voc\u00ea precisa avaliar o modelo de forma equilibrada, sem favorecer s\u00f3 recall ou s\u00f3 precis\u00e3o. Em sistemas de chatbots, o F1-score pode mostrar se o modelo est\u00e1 sendo eficiente em identificar inten\u00e7\u00f5es sem errar demais ou sem deixar passar intera\u00e7\u00f5es importantes.","title":"F1 Score:"},{"location":"Relatorios/avaliacaoChatbot/#fallback","text":"Em sistemas de chatbots com NLP (Processamento de Linguagem Natural), o termo fallback se refere \u00e0 resposta padr\u00e3o do sistema quando ele n\u00e3o consegue entender ou classificar corretamente a entrada do usu\u00e1rio. \u00c9, essencialmente, um mecanismo de seguran\u00e7a: quando o modelo n\u00e3o tem certeza sobre a inten\u00e7\u00e3o ou a confian\u00e7a da previs\u00e3o \u00e9 muito baixa, ele \"desiste\" de tentar responder de forma espec\u00edfica e ativa uma resposta gen\u00e9rica \u2014 como por exemplo: \u201cDesculpe, n\u00e3o entendi. Pode reformular?\u201d. Do ponto de vista t\u00e9cnico, o fallback \u00e9 ativado com base em limiares de confian\u00e7a (confidence threshold) definidos no modelo de classifica\u00e7\u00e3o. Se a previs\u00e3o da inten\u00e7\u00e3o do usu\u00e1rio n\u00e3o atingir esse limite m\u00ednimo de confian\u00e7a, o chatbot considera que \u00e9 melhor n\u00e3o arriscar uma resposta incorreta e, assim, retorna a resposta fallback. Embora o fallback seja uma prote\u00e7\u00e3o contra erros graves de interpreta\u00e7\u00e3o, ele tamb\u00e9m \u00e9 um sinal de limita\u00e7\u00e3o do modelo. Um n\u00famero alto de fallbacks pode indicar que: O modelo n\u00e3o est\u00e1 entendendo bem o vocabul\u00e1rio dos usu\u00e1rios; As inten\u00e7\u00f5es est\u00e3o mal definidas ou muito parecidas entre si; Os dados de treinamento s\u00e3o insuficientes ou mal distribu\u00eddos; O limiar de confian\u00e7a est\u00e1 muito alto, fazendo o modelo \"desistir\" com facilidade. A an\u00e1lise quantitativa do fallback pode ser feita simplesmente contando a frequ\u00eancia com que ele ocorre durante as intera\u00e7\u00f5es. Uma m\u00e9trica comum \u00e9: $ Taxa de Fallback = \\frac{N\u00famero\\ de\\ respostas\\ fallback}{N\u00famero\\ total\\ de\\ interac\u00f5es} $ Por exemplo, se um chatbot respondeu com fallback em 150 de 1.000 intera\u00e7\u00f5es, a taxa de fallback \u00e9 15%. A interpreta\u00e7\u00e3o do resultado da taxa de fallback depende do contexto. Em geral, uma taxa de fallback abaixo de 5% \u00e9 considerada boa para chatbots bem treinados. Taxas acima de 10% sinalizam que o modelo precisa de ajustes \u2014 seja nos dados, nas inten\u00e7\u00f5es ou nas regras de fallback.Em suma, o fallback \u00e9 um indicativo da robustez e cobertura do modelo.","title":"Fallback:"},{"location":"Relatorios/avaliacaoChatbot/#feedback-do-usuario","text":"O feedback do usu\u00e1rio \u00e9 uma das formas mais diretas e valiosas de avaliar se o modelo est\u00e1 cumprindo seu papel de forma eficaz. Diferentemente de m\u00e9tricas internas, como acur\u00e1cia ou recall, o feedback representa a percep\u00e7\u00e3o real do usu\u00e1rio sobre a qualidade da intera\u00e7\u00e3o \u2014 e, portanto, oferece uma perspectiva essencial para o aprimoramento cont\u00ednuo do sistema. O feedback pode ser expl\u00edcito, quando o usu\u00e1rio \u00e9 convidado a avaliar a resposta do chatbot (por exemplo, com bot\u00f5es de \ud83d\udc4d/\ud83d\udc4e ou uma escala de satisfa\u00e7\u00e3o), ou impl\u00edcito, quando o sistema infere a satisfa\u00e7\u00e3o com base em comportamentos, como repeti\u00e7\u00e3o da pergunta, abandono da conversa, ou solicita\u00e7\u00e3o direta por atendimento humano. Neste caso, consideramos o caso de avalia\u00e7\u00e3o expl\u00edcita. Esse retorno pode ser classificado, armazenado e analisado por meio de m\u00e9tricas como: $ Taxa\\ de\\ Satisfac\u00e3o = \\frac{N\u00famero\\ de\\ feedbacks\\ positivos}{Total\\ de\\ feedbacks\\ coletados} $ A interpreta\u00e7\u00e3o da taxa de satisfa\u00e7\u00e3o pode ser dada, genericamente, como: Acima de 85%: o chatbot est\u00e1 oferecendo uma experi\u00eancia positiva e confi\u00e1vel para a maioria dos usu\u00e1rios. Entre 60% e 85%: o sistema est\u00e1 funcional, mas h\u00e1 espa\u00e7o para ajustes nas respostas, tom de linguagem ou entendimento das inten\u00e7\u00f5es. Abaixo de 60%: sinal de alerta \u2014 o chatbot est\u00e1 frequentemente falhando em atender \u00e0s expectativas dos usu\u00e1rios. Por fim, vale destacar que a aus\u00eancia de feedback tamb\u00e9m deve ser monitorada. Se poucos usu\u00e1rios interagem com os mecanismos de avalia\u00e7\u00e3o, isso pode indicar que o sistema n\u00e3o est\u00e1 incentivando e facilitando essa intera\u00e7\u00e3o, o que prejudica o processo de melhoria cont\u00ednua.","title":"Feedback do usu\u00e1rio:"},{"location":"Relatorios/avaliacaoChatbot/#interpretacao-dos-resultados","text":"","title":"Interpreta\u00e7\u00e3o dos resultados"},{"location":"Relatorios/avaliacaoChatbot/#o-desempenho-geral-do-chatbot","text":"Para construirmos uma f\u00f3rmula geral de desempenho que venha a refletir todos os aspectos t\u00e9cnicos e de experi\u00eancia do usu\u00e1rio a partir de suas respectivas import\u00e2ncias atribu\u00eddas, teremos definidos, ent\u00e3o: A acur\u00e1cia como a propor\u00e7\u00e3o de classifica\u00e7\u00f5es corretas entre todas as previs\u00f5es F1-score como o equil\u00edbrio entre precis\u00e3o e recall Fallback como o indicador de falha na compreens\u00e3o Feedback do usu\u00e1rio como a avalia\u00e7\u00e3o qualitativa da experi\u00eancia do usu\u00e1rio E, por sua vez, a precis\u00e3o j\u00e1 est\u00e1 contida no F1-score, mas vamos destac\u00e1-la se for necess\u00e1rio ajustar. Sendo assim, a constru\u00e7\u00e3o de uma f\u00f3rmula geral d\u00e1-se por: $ Desempenho\\ Geral = 0.10 * F1score + 0.10 * (1 - Fallback) + 0.10 * Acur\u00e1cia + 0.70 * Feedback $ Onde: F1-score ser\u00e1 uma m\u00e9trica principal, refletindo a qualidade t\u00e9cnica do modelo. Taxa de fallback ser\u00e1 usada como penalidade (quanto mais alto o fallback, menor o desempenho). Acur\u00e1cia \u00e9 utilizada para verificar a propor\u00e7\u00e3o de classifica\u00e7\u00f5es corretas entre todas as previs\u00f5es. Feedback do usu\u00e1rio (de 0 a 1) ter\u00e1 peso 0.70, pois reflete diretamente a percep\u00e7\u00e3o de qualidade.","title":"O desempenho geral do chatbot:"},{"location":"Relatorios/avaliacaoChatbot/#referencias","text":"Izbicki, Rafael. Aprendizado de m\u00e1quina : uma abordagem estat\u00edstica [livro eletr\u00f4nico] / Rafael Izbicki, Tiago Mendon\u00e7a dos Santos. -- S\u00e3o Carlos, SP : Rafael Izbicki, 2020.","title":"Refer\u00eancias"},{"location":"Relatorios/relatorioCalculoGanhosAmbientais/","text":"Relat\u00f3rio referente ao processo de c\u00e1lculo de ganhos ambientais do SEI-RJ .rst-content .section .docutils { display: table; } figcaption { font-weight:bold; font-size: 16px; } Autores Beatriz Gomes de Souza Jos\u00e9 Hudson de Oliveira Guimar\u00e3es J\u00fanior Juliano Pais Canosa Portilho de Avellar Madalena Alves dos Santos Rodrigo Campos Martins Introdu\u00e7\u00e3o Em um mundo em que o avan\u00e7o tecnol\u00f3gico \u00e9 dado em acelera\u00e7\u00e3o crescente, a digitaliza\u00e7\u00e3o tem sido um processo que acomete todos os aspectos da vida humana. A transforma\u00e7\u00e3o digital, al\u00e9m de revolucionar a forma de comunica\u00e7\u00e3o e colabora\u00e7\u00e3o, apresenta-se como um aliado \u00e0 preserva\u00e7\u00e3o ambiental. Em termos gerais, a transi\u00e7\u00e3o do f\u00edsico para o digital pode ser destacada pelo seu papel de redu\u00e7\u00e3o de danos humanos ao planeta. Ao substituir documentos f\u00edsicos por arquivos digitais, descarta-se a necessidade de uso de mat\u00e9rias primas como papel, \u00e1gua e outros recursos, o que implica em menor apropria\u00e7\u00e3o de recursos naturais para operacionalidade das institui\u00e7\u00f5es. Al\u00e9m disso, a otimiza\u00e7\u00e3o de processos por meio da transforma\u00e7\u00e3o digital atrav\u00e9s de softwares e plataformas digitais diminui a necessidade de deslocamentos, contribuindo para a redu\u00e7\u00e3o das emiss\u00f5es de gases do efeito estufa. \u00c9 atrav\u00e9s de sistemas de monitoramento remoto que o acompanhamento do potencial redutor de consumo de bens naturais e o aumento da sa\u00fade de ecossistemas. Plataformas online, bem como o uso de softwares, p\u00e1ginas online, dentre outros, facilitam a visualiza\u00e7\u00e3o do consumo de mat\u00e9rias primas para o funcionamento das institui\u00e7\u00f5es, Dado a aplica\u00e7\u00e3o destas tecnologias, \u00e9 poss\u00edvel acelerar o desenvolvimento de solu\u00e7\u00f5es para os desafios ambientais. A digitaliza\u00e7\u00e3o est\u00e1 impulsionando o surgimento de um novo modelo de gest\u00e3o p\u00fablica, baseado no uso de tecnologias limpas e sustent\u00e1veis. A Secretaria de Estado de Transforma\u00e7\u00e3o Digital, bem como todos os \u00f3rg\u00e3os estaduais do Rio de Janeiro, embarcaram nesta empreitada com o uso do Sistema Eletr\u00f4nico de Informa\u00e7\u00f5es (SEI-RJ). O SEI-RJ, ou Sistema Eletr\u00f4nico de Informa\u00e7\u00f5es do Rio de Janeiro, \u00e9 uma plataforma digital desenvolvida para gerenciar de forma eficiente e segura processos administrativos e documentos eletr\u00f4nicos no estado do Rio de Janeiro. Atrav\u00e9s do sistema, os \u00f3rg\u00e3os p\u00fablicos estaduais podem automatizar tarefas como a cria\u00e7\u00e3o, edi\u00e7\u00e3o, assinatura e tramita\u00e7\u00e3o de documentos, reduzindo a burocracia e agilizando a tomada de decis\u00f5es. Essa ferramenta, baseada em um sistema j\u00e1 consolidado em outros tribunais, permite a integra\u00e7\u00e3o de diversas \u00e1reas e a colabora\u00e7\u00e3o entre diferentes setores, tornando os processos mais transparentes e rastre\u00e1veis. Historicamente, a produ\u00e7\u00e3o de material f\u00edsico pelas institui\u00e7\u00f5es p\u00fablicas \u00e9 destaque no \u00e2mbito do ac\u00famulo de material f\u00edsico. Para isso, o SEI-RJ funciona como um caminho promissor para a preserva\u00e7\u00e3o ambiental. Ao integrar tecnologias digitais em nossas vidas e em nossos neg\u00f3cios, podemos construir um futuro mais sustent\u00e1vel para as pr\u00f3ximas gera\u00e7\u00f5es. Este trabalho tem por objetivo apresentar a an\u00e1lise detalhada dos dados referentes ao SEI-RJ, de modo a demonstrar o potencial consider\u00e1vel de economia ambiental. Os c\u00e1lculos apresentados revelam que a implementa\u00e7\u00e3o e o uso cont\u00ednuo da plataforma resultam em uma redu\u00e7\u00e3o significativa no consumo de papel, energia e outros recursos naturais, al\u00e9m de minimizar a gera\u00e7\u00e3o de res\u00edduos. Os resultados aqui obtidos corroboram com a hip\u00f3tese de que a digitaliza\u00e7\u00e3o dos processos administrativos, ao otimizar fluxos de trabalho e eliminar a necessidade de impress\u00e3o, contribui de forma expressiva para a sustentabilidade ambiental. Conclui-se, portanto, que o SEI-RJ representa um instrumento eficaz para a promo\u00e7\u00e3o da economia circular e a constru\u00e7\u00e3o de um futuro mais verde para o estado do Rio de Janeiro Metodologia O c\u00e1lculo da economia ambiental gerada pelo SEI-RJ exige a ado\u00e7\u00e3o de uma metodologia espec\u00edfica que leve em considera\u00e7\u00e3o as particularidades do sistema e os diversos fatores que influenciam o consumo de recursos. A quantifica\u00e7\u00e3o dos benef\u00edcios ambientais de ferramentas digitais como o SEI apresenta desafios consider\u00e1veis, uma vez que envolve a estimativa de m\u00faltiplos indicadores e a considera\u00e7\u00e3o de diversos cen\u00e1rios. Inicialmente, a constru\u00e7\u00e3o do modelo de c\u00e1lculo deu-se a partir do processo de amostragem dos documentos dispon\u00edveis no sistema. O m\u00e9todo amostral utilizado durante esta etapa consistiu no uso da Amostragem Aleat\u00f3ria Simples (AAS) para determina\u00e7\u00e3o do tamanho da amostra considerado representativo. Desta maneira, a coleta dos dados amostrais foi realizada a partir do levantamento de documentos dispon\u00edveis no pr\u00f3prio sistema. Ap\u00f3s a an\u00e1lise documental, foi extra\u00eddo o n\u00famero total de p\u00e1ginas dos arquivos e o n\u00famero m\u00e9dio de p\u00e1ginas por documento baixado com o uso do software Python. Com a utiliza\u00e7\u00e3o de ferramentas de infer\u00eancia estat\u00edstica, foi poss\u00edvel verificar o n\u00edvel de confian\u00e7a e signific\u00e2ncia da pesquisa. Sendo assim, a amostra utilizada foi de 875 processos extra\u00eddos no SEI-RJ, totalizando 24334 p\u00e1ginas, com uma m\u00e9dia de p\u00e1ginas por arquivo de 27,81 p\u00e1ginas, com intervalo de confian\u00e7a de 95% e com margem de erro de mais ou menos 5% para mais ou para menos. Total de arquivos PDF: 875 Total de p\u00e1ginas: 24334 M\u00e9dia de p\u00e1ginas por arquivo: 27.81 O c\u00e1lculo de um intervalo de confian\u00e7a \u00e9 uma ferramenta estat\u00edstica utilizada para estimar o intervalo dentro do qual se espera que um par\u00e2metro populacional (como uma m\u00e9dia ou uma propor\u00e7\u00e3o) esteja, com um certo n\u00edvel de confian\u00e7a, baseado em uma amostra extra\u00edda dessa popula\u00e7\u00e3o. A ideia central \u00e9 fornecer uma faixa de valores plaus\u00edveis para o par\u00e2metro, ao inv\u00e9s de um \u00fanico valor espec\u00edfico, considerando a variabilidade da amostra. Todo o processo de c\u00e1lculo foi realizado utilizando o software Python, conforme demonstrado abaixo. ADICIONAR CODIGO COM JUNIOR No caso apresentado, o IC de 95% indica que h\u00e1 95% de certeza de que os resultados encontrados na amostra de 875 processos do SEI-RJ refletem a realidade de toda a popula\u00e7\u00e3o de processos. Essa medida permite aos pesquisadores generalizar suas conclus\u00f5es e ter mais confian\u00e7a na representatividade dos dados. A escolha da amostra de 875 processos n\u00e3o foi aleat\u00f3ria. Atrav\u00e9s de c\u00e1lculos estat\u00edsticos, os pesquisadores determinaram o tamanho ideal da amostra para garantir um n\u00edvel de confian\u00e7a e uma margem de erro aceit\u00e1veis. A margem de erro de 5% indica que o resultado obtido na amostra pode variar em at\u00e9 5% para mais ou para menos em rela\u00e7\u00e3o ao valor real da popula\u00e7\u00e3o. Essa precis\u00e3o \u00e9 essencial para tomar decis\u00f5es embasadas e evitar generaliza\u00e7\u00f5es equivocadas. Basicamente, o c\u00e1lculo do intervalo de confian\u00e7a para uma propor\u00e7\u00e3o utiliza a seguinte f\u00f3rmula: IC = p \u00b1 z * \u221a(p*(1-p)/n) Sendo assim, IC = 0,7 \u00b1 1,96 * \u221a(0,7*(1-0,7)/875) \u2248 0,7 \u00b1 0,029 O intervalo de confian\u00e7a foi de aproximadamente 0,671 a 0,729. Isso significa que temos 95% de confian\u00e7a de que a verdadeira propor\u00e7\u00e3o de processos na popula\u00e7\u00e3o total do SEI-RJ est\u00e1 entre 67,1% e 72,9%. Ou seja, \u00e9 poss\u00edvel afirmar com 95% de certeza que, se repet\u00edssemos a pesquisa com outras amostras aleat\u00f3rias do SEI-RJ, a propor\u00e7\u00e3o de processos encontrados em cada nova amostra estaria dentro desse intervalo. O intervalo de confian\u00e7a \u00e9 uma ferramenta importante porque oferece uma estimativa da incerteza associada \u00e0 estimativa de um par\u00e2metro. Ele \u00e9 especialmente \u00fatil quando n\u00e3o \u00e9 poss\u00edvel obter informa\u00e7\u00f5es sobre toda a popula\u00e7\u00e3o, permitindo tirar conclus\u00f5es sobre ela a partir de uma amostra. Al\u00e9m disso, ao inv\u00e9s de fornecer um \u00fanico valor (como uma m\u00e9dia pontual), o intervalo de confian\u00e7a d\u00e1 uma margem de erro, o que torna a infer\u00eancia mais precisa e robusta, levando em conta a variabilidade dos dados. Em resumo, o intervalo de confian\u00e7a serve para quantificar a precis\u00e3o de uma estimativa e comunicar a incerteza envolvida na estimativa de um par\u00e2metro populacional com base em dados amostrais. Com a finaliza\u00e7\u00e3o da an\u00e1lise dos dados amostrais, foi feito o c\u00e1lculo dos ganhos ambientais do sistema considerando 4 tipos de recursos ambientais, que s\u00e3o indiretamente utilizados na rotina administrativa da gest\u00e3o: \u00e1rvores, litros de \u00e1gua, mil/kw de energia e kg de CO\u00b2. Para cada um deles, foi associado um c\u00e1lculo num\u00e9rico espec\u00edfico, realizado por meio da ferramenta de BI Qlik Sense, que pode ser consultado por meio da tabela 1 1 . Tabela 1: C\u00e1lculo de ganhos ambientais por recurso ambiental \u00c1rvores Litros de \u00e1gua Mil/Kw de energia Kg de CO\u00b2 (COUNT (PROCESSO) x 27.81) x 0.00014 (COUNT (PROCESSO) x 27.81) x 0.5 (COUNT (PROCESSO) x 27.81) x 0.04 (COUNT (PROCESSO) x 27.81) x 0.00162 Todos os dados coletados e analisados foram cuidadosamente integrados ao painel de Business Intelligence, proporcionando uma visualiza\u00e7\u00e3o clara e din\u00e2mica dos ganhos ambientais alcan\u00e7ados. Ou seja, os dados de consumo de energia, gera\u00e7\u00e3o de res\u00edduos e emiss\u00f5es de gases do efeito estufa foram integrados ao painel BI, permitindo acompanhar em tempo real o desempenho ambiental de cada unidade de neg\u00f3cio. A utiliza\u00e7\u00e3o de testes de infer\u00eancia estat\u00edstica, como o que foi empregado nesta pesquisa, \u00e9 crucial para garantir a robustez dos resultados. Esses testes permitem aos pesquisadores fazer infer\u00eancias sobre a popula\u00e7\u00e3o a partir de uma amostra, quantificar a incerteza associada \u00e0s estimativas e comparar diferentes grupos ou tratamentos. No contexto da pesquisa em quest\u00e3o, o teste escolhido provavelmente foi um teste de propor\u00e7\u00e3o, adequado para estimar a propor\u00e7\u00e3o de processos com determinada caracter\u00edstica na popula\u00e7\u00e3o do SEI-RJ. Resultados Os resultados obtidos a partir da an\u00e1lise dos dados permitiram construir um panorama detalhado da performance ambiental do SEI-RJ. Essas informa\u00e7\u00f5es foram cuidadosamente integradas a um painel de Business Intelligence (BI), que se tornou uma ferramenta estrat\u00e9gica para a visualiza\u00e7\u00e3o e o acompanhamento dos avan\u00e7os em dire\u00e7\u00e3o \u00e0 sustentabilidade. O painel BI do SEI-RJ oferece uma interface intuitiva e personaliz\u00e1vel, permitindo que os usu\u00e1rios explorem diversos indicadores ambientais de forma interativa. Atrav\u00e9s de gr\u00e1ficos, tabelas e mapas, \u00e9 poss\u00edvel acompanhar em tempo real o consumo de recursos, a gera\u00e7\u00e3o de res\u00edduos, as emiss\u00f5es de gases do efeito estufa e outras m\u00e9tricas relevantes. Essa visualiza\u00e7\u00e3o clara e din\u00e2mica facilita a identifica\u00e7\u00e3o de tend\u00eancias, a compara\u00e7\u00e3o de resultados e a tomada de decis\u00f5es mais assertivas para a otimiza\u00e7\u00e3o dos processos e a redu\u00e7\u00e3o do impacto ambiental. Imagem 1. Painel SEI-RJ de ganhos ambientais. Basicamente, o painel possibilita que os resultados ambientais possam ser compartilhados de forma clara e objetiva com gestores, colaboradores e stakeholders, promovendo a transpar\u00eancia e o engajamento em torno das iniciativas de sustentabilidade. Ao cruzar diferentes indicadores e identificar padr\u00f5es, o painel BI auxilia na identifica\u00e7\u00e3o de oportunidades de melhoria e na defini\u00e7\u00e3o de metas mais ambiciosas. O acompanhamento em tempo real dos indicadores permite uma resposta r\u00e1pida a eventuais desvios e a implementa\u00e7\u00e3o de a\u00e7\u00f5es corretivas.O painel BI estimula uma cultura de melhoria cont\u00ednua, incentivando a busca por solu\u00e7\u00f5es inovadoras e a otimiza\u00e7\u00e3o dos processos. Logo, o painel BI \u00e9 um produto importante que contribui para uma gest\u00e3o p\u00fablica eficaz e ambientalmente respons\u00e1vel. Conclus\u00e3o Para consolidar os avan\u00e7os e garantir a sustentabilidade dos resultados obtidos, \u00e9 fundamental manter a alimenta\u00e7\u00e3o cont\u00ednua do painel BI com dados atualizados e precisos. Essa pr\u00e1tica assegura que a ferramenta continue sendo um retrato fiel da realidade ambiental do Estado e um guia estrat\u00e9gico para a tomada de decis\u00f5es. A disponibiliza\u00e7\u00e3o p\u00fablica dos dados e a intera\u00e7\u00e3o com \u00f3rg\u00e3os de pesquisa e a sociedade civil s\u00e3o cruciais para fomentar a colabora\u00e7\u00e3o e a constru\u00e7\u00e3o de solu\u00e7\u00f5es inovadoras. Ao compartilhar os resultados e estimular o debate, o SEI-RJ demonstra seu compromisso com a transpar\u00eancia e a participa\u00e7\u00e3o cidad\u00e3. Em suma, o painel BI representa um marco na gest\u00e3o ambiental do Estado, proporcionando um instrumento valioso para acompanhar os benef\u00edcios da transforma\u00e7\u00e3o digital e fortalecer a constru\u00e7\u00e3o de um futuro mais sustent\u00e1vel para todos. C\u00e1lculo de ganhos ambientais por recurso ambiental. Fonte: ChatGPT \u21a9","title":"Relat\u00f3rio referente ao processo de c\u00e1lculo de ganhos ambientais do SEI-RJ"},{"location":"Relatorios/relatorioCalculoGanhosAmbientais/#relatorio-referente-ao-processo-de-calculo-de-ganhos-ambientais-do-sei-rj","text":".rst-content .section .docutils { display: table; } figcaption { font-weight:bold; font-size: 16px; }","title":"Relat\u00f3rio referente ao processo de c\u00e1lculo de ganhos ambientais do SEI-RJ"},{"location":"Relatorios/relatorioCalculoGanhosAmbientais/#autores","text":"Beatriz Gomes de Souza Jos\u00e9 Hudson de Oliveira Guimar\u00e3es J\u00fanior Juliano Pais Canosa Portilho de Avellar Madalena Alves dos Santos Rodrigo Campos Martins","title":"Autores"},{"location":"Relatorios/relatorioCalculoGanhosAmbientais/#introducao","text":"Em um mundo em que o avan\u00e7o tecnol\u00f3gico \u00e9 dado em acelera\u00e7\u00e3o crescente, a digitaliza\u00e7\u00e3o tem sido um processo que acomete todos os aspectos da vida humana. A transforma\u00e7\u00e3o digital, al\u00e9m de revolucionar a forma de comunica\u00e7\u00e3o e colabora\u00e7\u00e3o, apresenta-se como um aliado \u00e0 preserva\u00e7\u00e3o ambiental. Em termos gerais, a transi\u00e7\u00e3o do f\u00edsico para o digital pode ser destacada pelo seu papel de redu\u00e7\u00e3o de danos humanos ao planeta. Ao substituir documentos f\u00edsicos por arquivos digitais, descarta-se a necessidade de uso de mat\u00e9rias primas como papel, \u00e1gua e outros recursos, o que implica em menor apropria\u00e7\u00e3o de recursos naturais para operacionalidade das institui\u00e7\u00f5es. Al\u00e9m disso, a otimiza\u00e7\u00e3o de processos por meio da transforma\u00e7\u00e3o digital atrav\u00e9s de softwares e plataformas digitais diminui a necessidade de deslocamentos, contribuindo para a redu\u00e7\u00e3o das emiss\u00f5es de gases do efeito estufa. \u00c9 atrav\u00e9s de sistemas de monitoramento remoto que o acompanhamento do potencial redutor de consumo de bens naturais e o aumento da sa\u00fade de ecossistemas. Plataformas online, bem como o uso de softwares, p\u00e1ginas online, dentre outros, facilitam a visualiza\u00e7\u00e3o do consumo de mat\u00e9rias primas para o funcionamento das institui\u00e7\u00f5es, Dado a aplica\u00e7\u00e3o destas tecnologias, \u00e9 poss\u00edvel acelerar o desenvolvimento de solu\u00e7\u00f5es para os desafios ambientais. A digitaliza\u00e7\u00e3o est\u00e1 impulsionando o surgimento de um novo modelo de gest\u00e3o p\u00fablica, baseado no uso de tecnologias limpas e sustent\u00e1veis. A Secretaria de Estado de Transforma\u00e7\u00e3o Digital, bem como todos os \u00f3rg\u00e3os estaduais do Rio de Janeiro, embarcaram nesta empreitada com o uso do Sistema Eletr\u00f4nico de Informa\u00e7\u00f5es (SEI-RJ). O SEI-RJ, ou Sistema Eletr\u00f4nico de Informa\u00e7\u00f5es do Rio de Janeiro, \u00e9 uma plataforma digital desenvolvida para gerenciar de forma eficiente e segura processos administrativos e documentos eletr\u00f4nicos no estado do Rio de Janeiro. Atrav\u00e9s do sistema, os \u00f3rg\u00e3os p\u00fablicos estaduais podem automatizar tarefas como a cria\u00e7\u00e3o, edi\u00e7\u00e3o, assinatura e tramita\u00e7\u00e3o de documentos, reduzindo a burocracia e agilizando a tomada de decis\u00f5es. Essa ferramenta, baseada em um sistema j\u00e1 consolidado em outros tribunais, permite a integra\u00e7\u00e3o de diversas \u00e1reas e a colabora\u00e7\u00e3o entre diferentes setores, tornando os processos mais transparentes e rastre\u00e1veis. Historicamente, a produ\u00e7\u00e3o de material f\u00edsico pelas institui\u00e7\u00f5es p\u00fablicas \u00e9 destaque no \u00e2mbito do ac\u00famulo de material f\u00edsico. Para isso, o SEI-RJ funciona como um caminho promissor para a preserva\u00e7\u00e3o ambiental. Ao integrar tecnologias digitais em nossas vidas e em nossos neg\u00f3cios, podemos construir um futuro mais sustent\u00e1vel para as pr\u00f3ximas gera\u00e7\u00f5es. Este trabalho tem por objetivo apresentar a an\u00e1lise detalhada dos dados referentes ao SEI-RJ, de modo a demonstrar o potencial consider\u00e1vel de economia ambiental. Os c\u00e1lculos apresentados revelam que a implementa\u00e7\u00e3o e o uso cont\u00ednuo da plataforma resultam em uma redu\u00e7\u00e3o significativa no consumo de papel, energia e outros recursos naturais, al\u00e9m de minimizar a gera\u00e7\u00e3o de res\u00edduos. Os resultados aqui obtidos corroboram com a hip\u00f3tese de que a digitaliza\u00e7\u00e3o dos processos administrativos, ao otimizar fluxos de trabalho e eliminar a necessidade de impress\u00e3o, contribui de forma expressiva para a sustentabilidade ambiental. Conclui-se, portanto, que o SEI-RJ representa um instrumento eficaz para a promo\u00e7\u00e3o da economia circular e a constru\u00e7\u00e3o de um futuro mais verde para o estado do Rio de Janeiro","title":"Introdu\u00e7\u00e3o"},{"location":"Relatorios/relatorioCalculoGanhosAmbientais/#metodologia","text":"O c\u00e1lculo da economia ambiental gerada pelo SEI-RJ exige a ado\u00e7\u00e3o de uma metodologia espec\u00edfica que leve em considera\u00e7\u00e3o as particularidades do sistema e os diversos fatores que influenciam o consumo de recursos. A quantifica\u00e7\u00e3o dos benef\u00edcios ambientais de ferramentas digitais como o SEI apresenta desafios consider\u00e1veis, uma vez que envolve a estimativa de m\u00faltiplos indicadores e a considera\u00e7\u00e3o de diversos cen\u00e1rios. Inicialmente, a constru\u00e7\u00e3o do modelo de c\u00e1lculo deu-se a partir do processo de amostragem dos documentos dispon\u00edveis no sistema. O m\u00e9todo amostral utilizado durante esta etapa consistiu no uso da Amostragem Aleat\u00f3ria Simples (AAS) para determina\u00e7\u00e3o do tamanho da amostra considerado representativo. Desta maneira, a coleta dos dados amostrais foi realizada a partir do levantamento de documentos dispon\u00edveis no pr\u00f3prio sistema. Ap\u00f3s a an\u00e1lise documental, foi extra\u00eddo o n\u00famero total de p\u00e1ginas dos arquivos e o n\u00famero m\u00e9dio de p\u00e1ginas por documento baixado com o uso do software Python. Com a utiliza\u00e7\u00e3o de ferramentas de infer\u00eancia estat\u00edstica, foi poss\u00edvel verificar o n\u00edvel de confian\u00e7a e signific\u00e2ncia da pesquisa. Sendo assim, a amostra utilizada foi de 875 processos extra\u00eddos no SEI-RJ, totalizando 24334 p\u00e1ginas, com uma m\u00e9dia de p\u00e1ginas por arquivo de 27,81 p\u00e1ginas, com intervalo de confian\u00e7a de 95% e com margem de erro de mais ou menos 5% para mais ou para menos. Total de arquivos PDF: 875 Total de p\u00e1ginas: 24334 M\u00e9dia de p\u00e1ginas por arquivo: 27.81 O c\u00e1lculo de um intervalo de confian\u00e7a \u00e9 uma ferramenta estat\u00edstica utilizada para estimar o intervalo dentro do qual se espera que um par\u00e2metro populacional (como uma m\u00e9dia ou uma propor\u00e7\u00e3o) esteja, com um certo n\u00edvel de confian\u00e7a, baseado em uma amostra extra\u00edda dessa popula\u00e7\u00e3o. A ideia central \u00e9 fornecer uma faixa de valores plaus\u00edveis para o par\u00e2metro, ao inv\u00e9s de um \u00fanico valor espec\u00edfico, considerando a variabilidade da amostra. Todo o processo de c\u00e1lculo foi realizado utilizando o software Python, conforme demonstrado abaixo. ADICIONAR CODIGO COM JUNIOR No caso apresentado, o IC de 95% indica que h\u00e1 95% de certeza de que os resultados encontrados na amostra de 875 processos do SEI-RJ refletem a realidade de toda a popula\u00e7\u00e3o de processos. Essa medida permite aos pesquisadores generalizar suas conclus\u00f5es e ter mais confian\u00e7a na representatividade dos dados. A escolha da amostra de 875 processos n\u00e3o foi aleat\u00f3ria. Atrav\u00e9s de c\u00e1lculos estat\u00edsticos, os pesquisadores determinaram o tamanho ideal da amostra para garantir um n\u00edvel de confian\u00e7a e uma margem de erro aceit\u00e1veis. A margem de erro de 5% indica que o resultado obtido na amostra pode variar em at\u00e9 5% para mais ou para menos em rela\u00e7\u00e3o ao valor real da popula\u00e7\u00e3o. Essa precis\u00e3o \u00e9 essencial para tomar decis\u00f5es embasadas e evitar generaliza\u00e7\u00f5es equivocadas. Basicamente, o c\u00e1lculo do intervalo de confian\u00e7a para uma propor\u00e7\u00e3o utiliza a seguinte f\u00f3rmula: IC = p \u00b1 z * \u221a(p*(1-p)/n) Sendo assim, IC = 0,7 \u00b1 1,96 * \u221a(0,7*(1-0,7)/875) \u2248 0,7 \u00b1 0,029 O intervalo de confian\u00e7a foi de aproximadamente 0,671 a 0,729. Isso significa que temos 95% de confian\u00e7a de que a verdadeira propor\u00e7\u00e3o de processos na popula\u00e7\u00e3o total do SEI-RJ est\u00e1 entre 67,1% e 72,9%. Ou seja, \u00e9 poss\u00edvel afirmar com 95% de certeza que, se repet\u00edssemos a pesquisa com outras amostras aleat\u00f3rias do SEI-RJ, a propor\u00e7\u00e3o de processos encontrados em cada nova amostra estaria dentro desse intervalo. O intervalo de confian\u00e7a \u00e9 uma ferramenta importante porque oferece uma estimativa da incerteza associada \u00e0 estimativa de um par\u00e2metro. Ele \u00e9 especialmente \u00fatil quando n\u00e3o \u00e9 poss\u00edvel obter informa\u00e7\u00f5es sobre toda a popula\u00e7\u00e3o, permitindo tirar conclus\u00f5es sobre ela a partir de uma amostra. Al\u00e9m disso, ao inv\u00e9s de fornecer um \u00fanico valor (como uma m\u00e9dia pontual), o intervalo de confian\u00e7a d\u00e1 uma margem de erro, o que torna a infer\u00eancia mais precisa e robusta, levando em conta a variabilidade dos dados. Em resumo, o intervalo de confian\u00e7a serve para quantificar a precis\u00e3o de uma estimativa e comunicar a incerteza envolvida na estimativa de um par\u00e2metro populacional com base em dados amostrais. Com a finaliza\u00e7\u00e3o da an\u00e1lise dos dados amostrais, foi feito o c\u00e1lculo dos ganhos ambientais do sistema considerando 4 tipos de recursos ambientais, que s\u00e3o indiretamente utilizados na rotina administrativa da gest\u00e3o: \u00e1rvores, litros de \u00e1gua, mil/kw de energia e kg de CO\u00b2. Para cada um deles, foi associado um c\u00e1lculo num\u00e9rico espec\u00edfico, realizado por meio da ferramenta de BI Qlik Sense, que pode ser consultado por meio da tabela 1 1 . Tabela 1: C\u00e1lculo de ganhos ambientais por recurso ambiental \u00c1rvores Litros de \u00e1gua Mil/Kw de energia Kg de CO\u00b2 (COUNT (PROCESSO) x 27.81) x 0.00014 (COUNT (PROCESSO) x 27.81) x 0.5 (COUNT (PROCESSO) x 27.81) x 0.04 (COUNT (PROCESSO) x 27.81) x 0.00162 Todos os dados coletados e analisados foram cuidadosamente integrados ao painel de Business Intelligence, proporcionando uma visualiza\u00e7\u00e3o clara e din\u00e2mica dos ganhos ambientais alcan\u00e7ados. Ou seja, os dados de consumo de energia, gera\u00e7\u00e3o de res\u00edduos e emiss\u00f5es de gases do efeito estufa foram integrados ao painel BI, permitindo acompanhar em tempo real o desempenho ambiental de cada unidade de neg\u00f3cio. A utiliza\u00e7\u00e3o de testes de infer\u00eancia estat\u00edstica, como o que foi empregado nesta pesquisa, \u00e9 crucial para garantir a robustez dos resultados. Esses testes permitem aos pesquisadores fazer infer\u00eancias sobre a popula\u00e7\u00e3o a partir de uma amostra, quantificar a incerteza associada \u00e0s estimativas e comparar diferentes grupos ou tratamentos. No contexto da pesquisa em quest\u00e3o, o teste escolhido provavelmente foi um teste de propor\u00e7\u00e3o, adequado para estimar a propor\u00e7\u00e3o de processos com determinada caracter\u00edstica na popula\u00e7\u00e3o do SEI-RJ.","title":"Metodologia"},{"location":"Relatorios/relatorioCalculoGanhosAmbientais/#resultados","text":"Os resultados obtidos a partir da an\u00e1lise dos dados permitiram construir um panorama detalhado da performance ambiental do SEI-RJ. Essas informa\u00e7\u00f5es foram cuidadosamente integradas a um painel de Business Intelligence (BI), que se tornou uma ferramenta estrat\u00e9gica para a visualiza\u00e7\u00e3o e o acompanhamento dos avan\u00e7os em dire\u00e7\u00e3o \u00e0 sustentabilidade. O painel BI do SEI-RJ oferece uma interface intuitiva e personaliz\u00e1vel, permitindo que os usu\u00e1rios explorem diversos indicadores ambientais de forma interativa. Atrav\u00e9s de gr\u00e1ficos, tabelas e mapas, \u00e9 poss\u00edvel acompanhar em tempo real o consumo de recursos, a gera\u00e7\u00e3o de res\u00edduos, as emiss\u00f5es de gases do efeito estufa e outras m\u00e9tricas relevantes. Essa visualiza\u00e7\u00e3o clara e din\u00e2mica facilita a identifica\u00e7\u00e3o de tend\u00eancias, a compara\u00e7\u00e3o de resultados e a tomada de decis\u00f5es mais assertivas para a otimiza\u00e7\u00e3o dos processos e a redu\u00e7\u00e3o do impacto ambiental. Imagem 1. Painel SEI-RJ de ganhos ambientais. Basicamente, o painel possibilita que os resultados ambientais possam ser compartilhados de forma clara e objetiva com gestores, colaboradores e stakeholders, promovendo a transpar\u00eancia e o engajamento em torno das iniciativas de sustentabilidade. Ao cruzar diferentes indicadores e identificar padr\u00f5es, o painel BI auxilia na identifica\u00e7\u00e3o de oportunidades de melhoria e na defini\u00e7\u00e3o de metas mais ambiciosas. O acompanhamento em tempo real dos indicadores permite uma resposta r\u00e1pida a eventuais desvios e a implementa\u00e7\u00e3o de a\u00e7\u00f5es corretivas.O painel BI estimula uma cultura de melhoria cont\u00ednua, incentivando a busca por solu\u00e7\u00f5es inovadoras e a otimiza\u00e7\u00e3o dos processos. Logo, o painel BI \u00e9 um produto importante que contribui para uma gest\u00e3o p\u00fablica eficaz e ambientalmente respons\u00e1vel.","title":"Resultados"},{"location":"Relatorios/relatorioCalculoGanhosAmbientais/#conclusao","text":"Para consolidar os avan\u00e7os e garantir a sustentabilidade dos resultados obtidos, \u00e9 fundamental manter a alimenta\u00e7\u00e3o cont\u00ednua do painel BI com dados atualizados e precisos. Essa pr\u00e1tica assegura que a ferramenta continue sendo um retrato fiel da realidade ambiental do Estado e um guia estrat\u00e9gico para a tomada de decis\u00f5es. A disponibiliza\u00e7\u00e3o p\u00fablica dos dados e a intera\u00e7\u00e3o com \u00f3rg\u00e3os de pesquisa e a sociedade civil s\u00e3o cruciais para fomentar a colabora\u00e7\u00e3o e a constru\u00e7\u00e3o de solu\u00e7\u00f5es inovadoras. Ao compartilhar os resultados e estimular o debate, o SEI-RJ demonstra seu compromisso com a transpar\u00eancia e a participa\u00e7\u00e3o cidad\u00e3. Em suma, o painel BI representa um marco na gest\u00e3o ambiental do Estado, proporcionando um instrumento valioso para acompanhar os benef\u00edcios da transforma\u00e7\u00e3o digital e fortalecer a constru\u00e7\u00e3o de um futuro mais sustent\u00e1vel para todos. C\u00e1lculo de ganhos ambientais por recurso ambiental. Fonte: ChatGPT \u21a9","title":"Conclus\u00e3o"},{"location":"Rotinas/extracaoTratamentoPainelSETD/","text":"extracao_tratamento_painel_SETD.py Objetivo Retirar certos dados das planinhas dos projetos do SETD, tratando-as e disponibilizando as informa\u00e7\u00f5es necess\u00e1rias para os pain\u00e9is interativos. Status Terminado. Funcionamento Para o funcionamento desta rotina s\u00e3o necess\u00e1rias as seguintes bibliotecas: import requests import openpyxl import pandas as pd import time from datetime import datetime O processo b\u00e1sico da rotina \u00e9 feito a seguir, nela recupera-se a planilha unificada do SETD do Google Docs e gera-se duas novas planilhas \"Oficial_Painel de Projetos SETD_Espec_CONCAT.xlsx\" e \"Oficial_Painel de Projetos SETD_Geral_CONCAT.xlsx\", uma com informa\u00e7\u00f5es gerais agregadas sobre os projetos do SETD e outra com informa\u00e7\u00f5es mais espec\u00edficas de cada projeto. Para explica\u00e7\u00e3o mais profunda acerca do funcionamento das fun\u00e7\u00f5es aqui apresentadas veja a se\u00e7\u00e3o Fun\u00e7\u00f5es . Abaixo podemos ver o significado de cada uma das vari\u00e1veis globais. today : vari\u00e1vel que armazena o dia de hoje. SPREADSHEET_ID : vari\u00e1vel que armazena o identificador da planilha google. OUTPUT_FILE : vari\u00e1vel que armazena o caminho onde ser\u00e1 guardado a planilha localmente. SELECTED_SHEETS : vari\u00e1vel que armazena as abas a serem recuperadas da planilha principal. Para a aquisi\u00e7\u00e3o do identificador da planilha google basta retirar a parte do url em negrito: https://docs.google.com/spreadsheets/d/ IDENTIFICADORDAPLANILHA /edit?hl=pt-br&gid=0#gid=0 # Obter a data atual today = datetime.now().date() # Configura\u00e7\u00f5es SPREADSHEET_ID = '19KZNNdg-P7T-JLkPkPzMJ_pJ9pEDuJziA4R--K8XKWY' OUTPUT_FILE = 'Z:/Paineis_Qlik_SETD/Painel_SETD/Painel_SETD_bruto.xlsx' SELECTED_SHEETS = ['ASSCOM', 'ASSTEC', 'PRODERJ', 'CHEGAB', 'SUPGDR', 'SUPIM', 'SUPPAE'] # Parte 1 download_google_sheet(SPREADSHEET_ID, OUTPUT_FILE) time.sleep(1) # Parte 2 wb = openpyxl.load_workbook(OUTPUT_FILE, data_only=True) remove_formatting(wb) time.sleep(1) # Parte 3 xlsx = pd.ExcelFile(OUTPUT_FILE) save_selected_sheets(xlsx, 'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Geral.xlsx', SELECTED_SHEETS) save_remaining_sheets(xlsx, 'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Espec.xlsx') time.sleep(1) # Parte 4 concatenate_sheets('Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Geral.xlsx', 'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Geral_CONCAT.xlsx') concatenate_sheets('Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Espec.xlsx', 'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Espec_CONCAT.xlsx') time.sleep(1) arquivo_geral = r'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Geral_CONCAT.xlsx' arquivo_especifico = r'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Espec_CONCAT.xlsx' resultado_geral, resultado_espec = generate_project_status(arquivo_geral, arquivo_especifico) print(f\"Arquivos salvos em {resultado_geral} e {resultado_espec}\") A rotina \u00e9 constituida de 7 fun\u00e7\u00f5es: download_google_sheet remove_formatting save_selected_sheets save_remaining_sheets concatenate_sheets determine_final_date generate_project_status Abaixo explicaremos cada uma delas de maneira detalhada. Fun\u00e7\u00f5es download_google_sheet A fun\u00e7\u00e3o download_google_sheet tem como objetivo baixar uma planilha google e salv\u00e1-la localmente. Ela recebe como par\u00e2metro de entrada duas vari\u00e1veis spreadsheet_id e output_file , representando a string do identificador da planilha e o caminho de onde o arquivo baixado dever\u00e1 ser salvo respectivamente. Seu funcionamento ocorre ao primeiro adicionarmos spreadsheet_id \u00e0 vari\u00e1vel url assim montando o link da planilha, com ele, utilizando a biblioteca requests, realizamos uma requisi\u00e7\u00e3o de download. A resposta dessa requisi\u00e7\u00e3o \u00e9 tratada de maneira que se houver erro seu c\u00f3digo \u00e9 impresso no terminal, caso contr\u00e1rio o conte\u00fado baixado \u00e9 armazenado no local e com o nome especificado por output_file . # Baixar o arquivo def download_google_sheet(spreadsheet_id, output_file): url = f'https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=xlsx' response = requests.get(url) assert response.status_code == 200, 'Erro ao baixar arquivo: status code {}'.format(response.status_code) with open(output_file, 'wb') as f: f.write(response.content) remove_formatting A fun\u00e7\u00e3o remove_formatting tem como objetivo formatar a planilha passada no par\u00e2metro workbook do tipo openpyxl.workbook.Workbook . Seu funcionamento ocorre ao percorremos todas as abas da planilha no primeiro loop e em todas as suas linhas no segundo retirando a formata\u00e7\u00e3o ao usarmos o m\u00e9todo iter_rows(values_only=True) . No final apenas salvamos a planilha no local indicado pela vari\u00e1vel global OUTPUT_FILE . # Retirar formata\u00e7\u00e3o da planilha def remove_formatting(workbook): for sheet in workbook: for row in sheet.iter_rows(values_only=True): pass workbook.save(OUTPUT_FILE) save_selected_sheets A fun\u00e7\u00e3o save_selected_sheets tem como objetivo separar certas abas de uma planilha e salv\u00e1-la em outra planilha. Ela recebe 3 par\u00e2metros de entrada xlsx , output_file e sheets onde o primeiro \u00e9 a planilha onde est\u00e3o as abas a serem separadas no formato xlsx , o segundo \u00e9 uma string com caminho onde dever\u00e1 ser salvo a nova planilha e o terceiro um array de strings com os nomes das abas selecionadas para separa\u00e7\u00e3o. Sua execu\u00e7\u00e3o come\u00e7a ao criarmos um objeto de escrita de um arquivo excel com o nome de writer , isso efetivamente cria o arquivo excel localmente. Seguindo temos um loop onde percorremos todos os nomes em sheets , salvando elas dentro da planilha criada anteriormente. # Escolher apenas as \"folhas\" necess\u00e1rias do arquivo bruto def save_selected_sheets(xlsx, output_file, sheets): with pd.ExcelWriter(output_file) as writer: for sheet in sheets: df = pd.read_excel(xlsx, sheet) df.to_excel(writer, sheet_name=sheet, index=False) save_remaining_sheets A fun\u00e7\u00e3o save_remaining_sheets , an\u00e1loga \u00e0quela anteriormente explicada, salva em uma planilha local as abas restantes da planilha original. Ela recebe 2 par\u00e2metros de entrada, xlsx e output_file , sendo eles um arquivo no formato xlsx e uma string com o local do arquivo a ser gerado. Seu funcionamento ocorre ao pularmos as 10 primeiras abas da planilha(as abas separadas pela fun\u00e7\u00e3o save_selected_sheets) e armazenando as abas restantes na planilha output_file . # Ignorar as 10 primeiras sheets def save_remaining_sheets(xlsx, output_file): with pd.ExcelWriter(output_file) as writer: for i in range(len(xlsx.sheet_names)): if i < 10: continue else: df = pd.read_excel(xlsx, xlsx.sheet_names[i]) df.to_excel(writer, sheet_name=xlsx.sheet_names[i], index=False) concatenate_sheets A fun\u00e7\u00e3o concatenate_sheets concatena as abas de um arquivo excel em uma \u00fanica aba. Ela recebe dois par\u00e2metros de entrada, input_file e output_file ambas strings com o caminho para arquivos excel, sendo o primeiro para um arquivo j\u00e1 existente e o segundo para a cria\u00e7\u00e3o de um novo. Seu funcionamento ocorre primeiro abrindo o arquivo input_file depois criando um array com o conte\u00fado das diferentes abas do arquivo ao final \u00e9 concatenado e salvo todas as abas em output_file . # Concatenar tudo para uma \u00fanica folha def concatenate_sheets(input_file, output_file): xlsx = pd.ExcelFile(input_file) dfs = [xlsx.parse(sheet) for sheet in xlsx.sheet_names] df_total = pd.concat(dfs, ignore_index=True) df_total.to_excel(output_file, index=False) determine_final_date A fun\u00e7\u00e3o determine_final_date recebe 3 par\u00e2metros de entrada, realizada , reprogramada e prevista , sendo elas de qualquer tipo, em nosso caso passamos strings . Ela tem como objetivo retornar o primeiro valor n\u00e3o nulo dos 3 par\u00e2metros iniciais na ordem: realizada , reprogramada e prevista . Se todas forem vazias, retorna None def determine_final_date(realizada, reprogramada, prevista): if pd.notna(realizada): return realizada elif pd.notna(reprogramada): return reprogramada elif pd.notna(prevista): return prevista else: return None generate_project_status A fun\u00e7\u00e3o generate_project_status tem como objetivo reformular 2 planilhas com as informa\u00e7\u00f5es dos projetos do SETD para atender as necessidades dos paineis informativos, sendo uma com informa\u00e7\u00f5es espec\u00edficas e outra com informa\u00e7\u00f5es gerais dos projetos. Ela recebe 2 par\u00e2metros de entrada, file_geral e file_especifico , o primeiro sendo o caminho para a planilha geral de projetos e o segundo para a planilha de projetos espec\u00edficos. Por ser uma fun\u00e7\u00e3o relativamente extensa faremos a explica\u00e7\u00e3o por partes. Essa primeira parte faz o tratamento dos dados e o agrupamento das planilhas passadas como argumento, eliminando processos marcados como exclu\u00eddos ou suspensos. Depois h\u00e1 uma filtragem das planilhas de projetos espec\u00edficos( df_espec ) para restarem apenas aqueles projetos que constam na planilha dos projetos gerais( df_geral ), seguido da contagem do total de projeto e a contagem daqueles que tem o status de conclu\u00eddo, guardando esses dois valores em um novo DataFrame chamado df_status_projetos . Posteriormente, adiciona-se uma coluna em df_status_projetos chamada \"Projeto Conclu\u00eddo\", onde marca-se aquele projeto conclu\u00eddo ou n\u00e3o com os valores \"VERDADEIRO\" e \"FALSO\". Com a tabela df_status_projetos definida, realiza-se uma mesclagem desta com df_geral baseada nos identificadores dos projetos, definindo os valores nulos como 0 ou \"FALSO\". def generate_project_status(file_geral, file_especifico): df_geral = pd.read_excel(file_geral, engine='openpyxl') # Excluindo as linhas com STATUS \"Suspenso\" ou \"Exclu\u00eddo\" df_geral = df_geral[~df_geral['STATUS'].isin(['Suspenso', 'Exclu\u00eddo'])] df_espec = pd.read_excel(file_especifico, engine='openpyxl') # Mantendo apenas as linhas no df_espec que t\u00eam correspond\u00eancia no df_geral df_espec = df_espec[df_espec[\"N\u00ba PROJETO\"].isin(df_geral[\"N\u00ba\"])] etapas_total = df_espec[df_espec[\"DESCRI\u00c7\u00c3O ETAPA\"].notna()].groupby('N\u00ba PROJETO').size() etapas_concluidas = df_espec[df_espec[\"CONCLU\u00cdDA\"] == \"Sim\"].groupby('N\u00ba PROJETO').size() df_status_projetos = pd.DataFrame({ 'Total de Etapas': etapas_total, 'Etapas Conclu\u00eddas': etapas_concluidas }).fillna(0) df_status_projetos['Projeto Conclu\u00eddo'] = (df_status_projetos['Total de Etapas'] == df_status_projetos['Etapas Conclu\u00eddas']).replace({True: 'VERDADEIRO', False: 'FALSO'}) df_geral = df_geral.merge(df_status_projetos, left_on=\"N\u00ba\", right_index=True, how=\"left\") df_geral[['Total de Etapas', 'Etapas Conclu\u00eddas', 'Projeto Conclu\u00eddo']] = df_geral[['Total de Etapas', 'Etapas Conclu\u00eddas', 'Projeto Conclu\u00eddo']].fillna({\"Total de Etapas\": 0, \"Etapas Conclu\u00eddas\": 0, \"Projeto Conclu\u00eddo\": 'FALSO'}) Em seguida adiciona-se duas colunas em df_espec as colunas 'Data In\u00edcio (Final)' e 'Data Fim (Final)' com o aux\u00edlio da fun\u00e7\u00e3o determine_final_date adicionando as datas relevantes em seus espa\u00e7os espec\u00edficos, com esses dados preenchidos realizamos a conta de dura\u00e7\u00e3o do projeto e guardamos em uma coluna de nome \"Dias de Dura\u00e7\u00e3o\". df_espec['Data In\u00edcio (Final)'] = df_espec.apply(lambda row: determine_final_date(row['DATA IN\u00cdCIO (realizada)'], row['DATA IN\u00cdCIO (reprogramada)'], row['DATA IN\u00cdCIO (prevista)']), axis=1) df_espec['Data Fim (Final)'] = df_espec.apply(lambda row: determine_final_date(row['DATA FIM (realizada)'], row['DATA FIM (reprogramada)'], row['DATA FIM (prevista)']), axis=1) df_espec[\"Data In\u00edcio (Final)\"] = pd.to_datetime(df_espec[\"Data In\u00edcio (Final)\"], errors='coerce') df_espec[\"Data Fim (Final)\"] = pd.to_datetime(df_espec[\"Data Fim (Final)\"], errors='coerce') df_espec[\"Dias de Dura\u00e7\u00e3o\"] = (df_espec[\"Data Fim (Final)\"] - df_espec[\"Data In\u00edcio (Final)\"]).dt.days mask_erro = (df_espec[\"Data In\u00edcio (Final)\"].isnull() & df_espec[\"Data Fim (Final)\"].notnull()) | \\ (df_espec[\"Data In\u00edcio (Final)\"].notnull() & df_espec[\"Data Fim (Final)\"].isnull()) df_espec.loc[mask_erro, \"Dias de Dura\u00e7\u00e3o\"] = \"ERRO\" Com essas informa\u00e7\u00f5es especificadas em df_espec , \u00e9 feito a verifica\u00e7\u00e3o o estado do projeto atr\u00e1ves da fun\u00e7\u00e3o determine_due_status podendo ter 3 valores \"None\" para se o projeto j\u00e1 ter sido conclu\u00eddo, \"atrasado\" ou \"no prazo\", essa informa\u00e7\u00e3o \u00e9 guardada na coluna \"Status prazo\". Depois agrupa-se na vari\u00e1vel project_status os projetos pelos seus identificadores e define-se o status geral do projeto, sendo salva essa informa\u00e7\u00e3o em df_geral com o nome \"Status Geral Prazo\". # Adicionando a coluna 'Status Prazo' com a l\u00f3gica especificada def determine_due_status(row): if pd.isna(row['Data Fim (Final)']) or pd.isna(row['CONCLU\u00cdDA']): return None # Campo em branco se alguma das colunas estiver vazia elif row['Data Fim (Final)'].date() < today and row['CONCLU\u00cdDA'] == \"N\u00e3o\": return \"atrasado\" else: return \"no prazo\" df_espec['Status Prazo'] = df_espec.apply(determine_due_status, axis=1) # Agrupe a coluna \"Status Prazo\" do df_espec por \"N\u00ba PROJETO\" e determine o status geral def project_due_status(group): # Filtrando apenas valores que n\u00e3o s\u00e3o None valid_statuses = [status for status in group if pd.notna(status)] # Se n\u00e3o houver nenhum status v\u00e1lido, retorna None if not valid_statuses: return None # Se todos os valores v\u00e1lidos forem \"no prazo\", retorna \"no prazo\" elif all(status == \"no prazo\" for status in valid_statuses): return \"no prazo\" # Se houver algum valor \"atrasado\" entre os valores v\u00e1lidos, retorna \"atrasado\" else: return \"atrasado\" project_status = df_espec.groupby('N\u00ba PROJETO')['Status Prazo'].apply(project_due_status) # Junte o resultado com o df_geral df_geral = df_geral.merge(project_status, left_on='N\u00ba', right_index=True, how='left') df_geral.rename(columns={'Status Prazo': 'Status Geral Prazo'}, inplace=True) Por fim, acumula-se a dura\u00e7\u00e3o de cada etapa do projeto na vari\u00e1vel total_dias_por_projeto e o valor total de cada processo em total_dias_etapas_concluidas , a fim de realizar a propor\u00e7\u00e3o de cada etapa do projeto em rela\u00e7\u00e3o ao seu todo, essa estat\u00edstica \u00e9 guardada na coluna \"% Conclu\u00eddo\" na tabela df_geral . Por fim escrevos o df_geral e o df_espec , em output_geral e output_espec devolvendo esses caminhos como retorno da fun\u00e7\u00e3o. df_espec['Dias de Dura\u00e7\u00e3o Float'] = df_espec['Dias de Dura\u00e7\u00e3o'].apply(convert_to_float) total_dias_por_projeto = df_espec.groupby('N\u00ba PROJETO')['Dias de Dura\u00e7\u00e3o Float'].sum() df_etapas_concluidas = df_espec[df_espec[\"CONCLU\u00cdDA\"] == \"Sim\"] total_dias_etapas_concluidas = df_etapas_concluidas.groupby('N\u00ba PROJETO')['Dias de Dura\u00e7\u00e3o Float'].sum() df_geral['% Conclu\u00eddo'] = df_geral['N\u00ba'].apply(lambda x: (total_dias_etapas_concluidas.get(x, 0) / (total_dias_por_projeto.get(x, 1))) if total_dias_por_projeto.get(x, 1) != 0 else 0) output_geral = r'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Geral_CONCAT.xlsx' output_espec = r'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Espec_CONCAT.xlsx' df_geral.to_excel(output_geral, index=False, engine='openpyxl') df_espec.drop(columns=['Dias de Dura\u00e7\u00e3o Float'], inplace=True) df_espec.to_excel(output_espec, index=False, engine='openpyxl') return output_geral, output_espec","title":"extracao_tratamento_painel_SETD.py"},{"location":"Rotinas/extracaoTratamentoPainelSETD/#extracao_tratamento_painel_setdpy","text":"","title":"extracao_tratamento_painel_SETD.py"},{"location":"Rotinas/extracaoTratamentoPainelSETD/#objetivo","text":"Retirar certos dados das planinhas dos projetos do SETD, tratando-as e disponibilizando as informa\u00e7\u00f5es necess\u00e1rias para os pain\u00e9is interativos.","title":"Objetivo"},{"location":"Rotinas/extracaoTratamentoPainelSETD/#status","text":"Terminado.","title":"Status"},{"location":"Rotinas/extracaoTratamentoPainelSETD/#funcionamento","text":"Para o funcionamento desta rotina s\u00e3o necess\u00e1rias as seguintes bibliotecas: import requests import openpyxl import pandas as pd import time from datetime import datetime O processo b\u00e1sico da rotina \u00e9 feito a seguir, nela recupera-se a planilha unificada do SETD do Google Docs e gera-se duas novas planilhas \"Oficial_Painel de Projetos SETD_Espec_CONCAT.xlsx\" e \"Oficial_Painel de Projetos SETD_Geral_CONCAT.xlsx\", uma com informa\u00e7\u00f5es gerais agregadas sobre os projetos do SETD e outra com informa\u00e7\u00f5es mais espec\u00edficas de cada projeto. Para explica\u00e7\u00e3o mais profunda acerca do funcionamento das fun\u00e7\u00f5es aqui apresentadas veja a se\u00e7\u00e3o Fun\u00e7\u00f5es . Abaixo podemos ver o significado de cada uma das vari\u00e1veis globais. today : vari\u00e1vel que armazena o dia de hoje. SPREADSHEET_ID : vari\u00e1vel que armazena o identificador da planilha google. OUTPUT_FILE : vari\u00e1vel que armazena o caminho onde ser\u00e1 guardado a planilha localmente. SELECTED_SHEETS : vari\u00e1vel que armazena as abas a serem recuperadas da planilha principal. Para a aquisi\u00e7\u00e3o do identificador da planilha google basta retirar a parte do url em negrito: https://docs.google.com/spreadsheets/d/ IDENTIFICADORDAPLANILHA /edit?hl=pt-br&gid=0#gid=0 # Obter a data atual today = datetime.now().date() # Configura\u00e7\u00f5es SPREADSHEET_ID = '19KZNNdg-P7T-JLkPkPzMJ_pJ9pEDuJziA4R--K8XKWY' OUTPUT_FILE = 'Z:/Paineis_Qlik_SETD/Painel_SETD/Painel_SETD_bruto.xlsx' SELECTED_SHEETS = ['ASSCOM', 'ASSTEC', 'PRODERJ', 'CHEGAB', 'SUPGDR', 'SUPIM', 'SUPPAE'] # Parte 1 download_google_sheet(SPREADSHEET_ID, OUTPUT_FILE) time.sleep(1) # Parte 2 wb = openpyxl.load_workbook(OUTPUT_FILE, data_only=True) remove_formatting(wb) time.sleep(1) # Parte 3 xlsx = pd.ExcelFile(OUTPUT_FILE) save_selected_sheets(xlsx, 'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Geral.xlsx', SELECTED_SHEETS) save_remaining_sheets(xlsx, 'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Espec.xlsx') time.sleep(1) # Parte 4 concatenate_sheets('Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Geral.xlsx', 'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Geral_CONCAT.xlsx') concatenate_sheets('Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Espec.xlsx', 'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Espec_CONCAT.xlsx') time.sleep(1) arquivo_geral = r'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Geral_CONCAT.xlsx' arquivo_especifico = r'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Espec_CONCAT.xlsx' resultado_geral, resultado_espec = generate_project_status(arquivo_geral, arquivo_especifico) print(f\"Arquivos salvos em {resultado_geral} e {resultado_espec}\") A rotina \u00e9 constituida de 7 fun\u00e7\u00f5es: download_google_sheet remove_formatting save_selected_sheets save_remaining_sheets concatenate_sheets determine_final_date generate_project_status Abaixo explicaremos cada uma delas de maneira detalhada.","title":"Funcionamento"},{"location":"Rotinas/extracaoTratamentoPainelSETD/#funcoes","text":"","title":"Fun\u00e7\u00f5es"},{"location":"Rotinas/extracaoTratamentoPainelSETD/#download_google_sheet","text":"A fun\u00e7\u00e3o download_google_sheet tem como objetivo baixar uma planilha google e salv\u00e1-la localmente. Ela recebe como par\u00e2metro de entrada duas vari\u00e1veis spreadsheet_id e output_file , representando a string do identificador da planilha e o caminho de onde o arquivo baixado dever\u00e1 ser salvo respectivamente. Seu funcionamento ocorre ao primeiro adicionarmos spreadsheet_id \u00e0 vari\u00e1vel url assim montando o link da planilha, com ele, utilizando a biblioteca requests, realizamos uma requisi\u00e7\u00e3o de download. A resposta dessa requisi\u00e7\u00e3o \u00e9 tratada de maneira que se houver erro seu c\u00f3digo \u00e9 impresso no terminal, caso contr\u00e1rio o conte\u00fado baixado \u00e9 armazenado no local e com o nome especificado por output_file . # Baixar o arquivo def download_google_sheet(spreadsheet_id, output_file): url = f'https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=xlsx' response = requests.get(url) assert response.status_code == 200, 'Erro ao baixar arquivo: status code {}'.format(response.status_code) with open(output_file, 'wb') as f: f.write(response.content)","title":"download_google_sheet"},{"location":"Rotinas/extracaoTratamentoPainelSETD/#remove_formatting","text":"A fun\u00e7\u00e3o remove_formatting tem como objetivo formatar a planilha passada no par\u00e2metro workbook do tipo openpyxl.workbook.Workbook . Seu funcionamento ocorre ao percorremos todas as abas da planilha no primeiro loop e em todas as suas linhas no segundo retirando a formata\u00e7\u00e3o ao usarmos o m\u00e9todo iter_rows(values_only=True) . No final apenas salvamos a planilha no local indicado pela vari\u00e1vel global OUTPUT_FILE . # Retirar formata\u00e7\u00e3o da planilha def remove_formatting(workbook): for sheet in workbook: for row in sheet.iter_rows(values_only=True): pass workbook.save(OUTPUT_FILE)","title":"remove_formatting"},{"location":"Rotinas/extracaoTratamentoPainelSETD/#save_selected_sheets","text":"A fun\u00e7\u00e3o save_selected_sheets tem como objetivo separar certas abas de uma planilha e salv\u00e1-la em outra planilha. Ela recebe 3 par\u00e2metros de entrada xlsx , output_file e sheets onde o primeiro \u00e9 a planilha onde est\u00e3o as abas a serem separadas no formato xlsx , o segundo \u00e9 uma string com caminho onde dever\u00e1 ser salvo a nova planilha e o terceiro um array de strings com os nomes das abas selecionadas para separa\u00e7\u00e3o. Sua execu\u00e7\u00e3o come\u00e7a ao criarmos um objeto de escrita de um arquivo excel com o nome de writer , isso efetivamente cria o arquivo excel localmente. Seguindo temos um loop onde percorremos todos os nomes em sheets , salvando elas dentro da planilha criada anteriormente. # Escolher apenas as \"folhas\" necess\u00e1rias do arquivo bruto def save_selected_sheets(xlsx, output_file, sheets): with pd.ExcelWriter(output_file) as writer: for sheet in sheets: df = pd.read_excel(xlsx, sheet) df.to_excel(writer, sheet_name=sheet, index=False)","title":"save_selected_sheets"},{"location":"Rotinas/extracaoTratamentoPainelSETD/#save_remaining_sheets","text":"A fun\u00e7\u00e3o save_remaining_sheets , an\u00e1loga \u00e0quela anteriormente explicada, salva em uma planilha local as abas restantes da planilha original. Ela recebe 2 par\u00e2metros de entrada, xlsx e output_file , sendo eles um arquivo no formato xlsx e uma string com o local do arquivo a ser gerado. Seu funcionamento ocorre ao pularmos as 10 primeiras abas da planilha(as abas separadas pela fun\u00e7\u00e3o save_selected_sheets) e armazenando as abas restantes na planilha output_file . # Ignorar as 10 primeiras sheets def save_remaining_sheets(xlsx, output_file): with pd.ExcelWriter(output_file) as writer: for i in range(len(xlsx.sheet_names)): if i < 10: continue else: df = pd.read_excel(xlsx, xlsx.sheet_names[i]) df.to_excel(writer, sheet_name=xlsx.sheet_names[i], index=False)","title":"save_remaining_sheets"},{"location":"Rotinas/extracaoTratamentoPainelSETD/#concatenate_sheets","text":"A fun\u00e7\u00e3o concatenate_sheets concatena as abas de um arquivo excel em uma \u00fanica aba. Ela recebe dois par\u00e2metros de entrada, input_file e output_file ambas strings com o caminho para arquivos excel, sendo o primeiro para um arquivo j\u00e1 existente e o segundo para a cria\u00e7\u00e3o de um novo. Seu funcionamento ocorre primeiro abrindo o arquivo input_file depois criando um array com o conte\u00fado das diferentes abas do arquivo ao final \u00e9 concatenado e salvo todas as abas em output_file . # Concatenar tudo para uma \u00fanica folha def concatenate_sheets(input_file, output_file): xlsx = pd.ExcelFile(input_file) dfs = [xlsx.parse(sheet) for sheet in xlsx.sheet_names] df_total = pd.concat(dfs, ignore_index=True) df_total.to_excel(output_file, index=False)","title":"concatenate_sheets"},{"location":"Rotinas/extracaoTratamentoPainelSETD/#determine_final_date","text":"A fun\u00e7\u00e3o determine_final_date recebe 3 par\u00e2metros de entrada, realizada , reprogramada e prevista , sendo elas de qualquer tipo, em nosso caso passamos strings . Ela tem como objetivo retornar o primeiro valor n\u00e3o nulo dos 3 par\u00e2metros iniciais na ordem: realizada , reprogramada e prevista . Se todas forem vazias, retorna None def determine_final_date(realizada, reprogramada, prevista): if pd.notna(realizada): return realizada elif pd.notna(reprogramada): return reprogramada elif pd.notna(prevista): return prevista else: return None","title":"determine_final_date"},{"location":"Rotinas/extracaoTratamentoPainelSETD/#generate_project_status","text":"A fun\u00e7\u00e3o generate_project_status tem como objetivo reformular 2 planilhas com as informa\u00e7\u00f5es dos projetos do SETD para atender as necessidades dos paineis informativos, sendo uma com informa\u00e7\u00f5es espec\u00edficas e outra com informa\u00e7\u00f5es gerais dos projetos. Ela recebe 2 par\u00e2metros de entrada, file_geral e file_especifico , o primeiro sendo o caminho para a planilha geral de projetos e o segundo para a planilha de projetos espec\u00edficos. Por ser uma fun\u00e7\u00e3o relativamente extensa faremos a explica\u00e7\u00e3o por partes. Essa primeira parte faz o tratamento dos dados e o agrupamento das planilhas passadas como argumento, eliminando processos marcados como exclu\u00eddos ou suspensos. Depois h\u00e1 uma filtragem das planilhas de projetos espec\u00edficos( df_espec ) para restarem apenas aqueles projetos que constam na planilha dos projetos gerais( df_geral ), seguido da contagem do total de projeto e a contagem daqueles que tem o status de conclu\u00eddo, guardando esses dois valores em um novo DataFrame chamado df_status_projetos . Posteriormente, adiciona-se uma coluna em df_status_projetos chamada \"Projeto Conclu\u00eddo\", onde marca-se aquele projeto conclu\u00eddo ou n\u00e3o com os valores \"VERDADEIRO\" e \"FALSO\". Com a tabela df_status_projetos definida, realiza-se uma mesclagem desta com df_geral baseada nos identificadores dos projetos, definindo os valores nulos como 0 ou \"FALSO\". def generate_project_status(file_geral, file_especifico): df_geral = pd.read_excel(file_geral, engine='openpyxl') # Excluindo as linhas com STATUS \"Suspenso\" ou \"Exclu\u00eddo\" df_geral = df_geral[~df_geral['STATUS'].isin(['Suspenso', 'Exclu\u00eddo'])] df_espec = pd.read_excel(file_especifico, engine='openpyxl') # Mantendo apenas as linhas no df_espec que t\u00eam correspond\u00eancia no df_geral df_espec = df_espec[df_espec[\"N\u00ba PROJETO\"].isin(df_geral[\"N\u00ba\"])] etapas_total = df_espec[df_espec[\"DESCRI\u00c7\u00c3O ETAPA\"].notna()].groupby('N\u00ba PROJETO').size() etapas_concluidas = df_espec[df_espec[\"CONCLU\u00cdDA\"] == \"Sim\"].groupby('N\u00ba PROJETO').size() df_status_projetos = pd.DataFrame({ 'Total de Etapas': etapas_total, 'Etapas Conclu\u00eddas': etapas_concluidas }).fillna(0) df_status_projetos['Projeto Conclu\u00eddo'] = (df_status_projetos['Total de Etapas'] == df_status_projetos['Etapas Conclu\u00eddas']).replace({True: 'VERDADEIRO', False: 'FALSO'}) df_geral = df_geral.merge(df_status_projetos, left_on=\"N\u00ba\", right_index=True, how=\"left\") df_geral[['Total de Etapas', 'Etapas Conclu\u00eddas', 'Projeto Conclu\u00eddo']] = df_geral[['Total de Etapas', 'Etapas Conclu\u00eddas', 'Projeto Conclu\u00eddo']].fillna({\"Total de Etapas\": 0, \"Etapas Conclu\u00eddas\": 0, \"Projeto Conclu\u00eddo\": 'FALSO'}) Em seguida adiciona-se duas colunas em df_espec as colunas 'Data In\u00edcio (Final)' e 'Data Fim (Final)' com o aux\u00edlio da fun\u00e7\u00e3o determine_final_date adicionando as datas relevantes em seus espa\u00e7os espec\u00edficos, com esses dados preenchidos realizamos a conta de dura\u00e7\u00e3o do projeto e guardamos em uma coluna de nome \"Dias de Dura\u00e7\u00e3o\". df_espec['Data In\u00edcio (Final)'] = df_espec.apply(lambda row: determine_final_date(row['DATA IN\u00cdCIO (realizada)'], row['DATA IN\u00cdCIO (reprogramada)'], row['DATA IN\u00cdCIO (prevista)']), axis=1) df_espec['Data Fim (Final)'] = df_espec.apply(lambda row: determine_final_date(row['DATA FIM (realizada)'], row['DATA FIM (reprogramada)'], row['DATA FIM (prevista)']), axis=1) df_espec[\"Data In\u00edcio (Final)\"] = pd.to_datetime(df_espec[\"Data In\u00edcio (Final)\"], errors='coerce') df_espec[\"Data Fim (Final)\"] = pd.to_datetime(df_espec[\"Data Fim (Final)\"], errors='coerce') df_espec[\"Dias de Dura\u00e7\u00e3o\"] = (df_espec[\"Data Fim (Final)\"] - df_espec[\"Data In\u00edcio (Final)\"]).dt.days mask_erro = (df_espec[\"Data In\u00edcio (Final)\"].isnull() & df_espec[\"Data Fim (Final)\"].notnull()) | \\ (df_espec[\"Data In\u00edcio (Final)\"].notnull() & df_espec[\"Data Fim (Final)\"].isnull()) df_espec.loc[mask_erro, \"Dias de Dura\u00e7\u00e3o\"] = \"ERRO\" Com essas informa\u00e7\u00f5es especificadas em df_espec , \u00e9 feito a verifica\u00e7\u00e3o o estado do projeto atr\u00e1ves da fun\u00e7\u00e3o determine_due_status podendo ter 3 valores \"None\" para se o projeto j\u00e1 ter sido conclu\u00eddo, \"atrasado\" ou \"no prazo\", essa informa\u00e7\u00e3o \u00e9 guardada na coluna \"Status prazo\". Depois agrupa-se na vari\u00e1vel project_status os projetos pelos seus identificadores e define-se o status geral do projeto, sendo salva essa informa\u00e7\u00e3o em df_geral com o nome \"Status Geral Prazo\". # Adicionando a coluna 'Status Prazo' com a l\u00f3gica especificada def determine_due_status(row): if pd.isna(row['Data Fim (Final)']) or pd.isna(row['CONCLU\u00cdDA']): return None # Campo em branco se alguma das colunas estiver vazia elif row['Data Fim (Final)'].date() < today and row['CONCLU\u00cdDA'] == \"N\u00e3o\": return \"atrasado\" else: return \"no prazo\" df_espec['Status Prazo'] = df_espec.apply(determine_due_status, axis=1) # Agrupe a coluna \"Status Prazo\" do df_espec por \"N\u00ba PROJETO\" e determine o status geral def project_due_status(group): # Filtrando apenas valores que n\u00e3o s\u00e3o None valid_statuses = [status for status in group if pd.notna(status)] # Se n\u00e3o houver nenhum status v\u00e1lido, retorna None if not valid_statuses: return None # Se todos os valores v\u00e1lidos forem \"no prazo\", retorna \"no prazo\" elif all(status == \"no prazo\" for status in valid_statuses): return \"no prazo\" # Se houver algum valor \"atrasado\" entre os valores v\u00e1lidos, retorna \"atrasado\" else: return \"atrasado\" project_status = df_espec.groupby('N\u00ba PROJETO')['Status Prazo'].apply(project_due_status) # Junte o resultado com o df_geral df_geral = df_geral.merge(project_status, left_on='N\u00ba', right_index=True, how='left') df_geral.rename(columns={'Status Prazo': 'Status Geral Prazo'}, inplace=True) Por fim, acumula-se a dura\u00e7\u00e3o de cada etapa do projeto na vari\u00e1vel total_dias_por_projeto e o valor total de cada processo em total_dias_etapas_concluidas , a fim de realizar a propor\u00e7\u00e3o de cada etapa do projeto em rela\u00e7\u00e3o ao seu todo, essa estat\u00edstica \u00e9 guardada na coluna \"% Conclu\u00eddo\" na tabela df_geral . Por fim escrevos o df_geral e o df_espec , em output_geral e output_espec devolvendo esses caminhos como retorno da fun\u00e7\u00e3o. df_espec['Dias de Dura\u00e7\u00e3o Float'] = df_espec['Dias de Dura\u00e7\u00e3o'].apply(convert_to_float) total_dias_por_projeto = df_espec.groupby('N\u00ba PROJETO')['Dias de Dura\u00e7\u00e3o Float'].sum() df_etapas_concluidas = df_espec[df_espec[\"CONCLU\u00cdDA\"] == \"Sim\"] total_dias_etapas_concluidas = df_etapas_concluidas.groupby('N\u00ba PROJETO')['Dias de Dura\u00e7\u00e3o Float'].sum() df_geral['% Conclu\u00eddo'] = df_geral['N\u00ba'].apply(lambda x: (total_dias_etapas_concluidas.get(x, 0) / (total_dias_por_projeto.get(x, 1))) if total_dias_por_projeto.get(x, 1) != 0 else 0) output_geral = r'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Geral_CONCAT.xlsx' output_espec = r'Z:/Paineis_Qlik_SETD/Painel_SETD/Oficial_Painel de Projetos SETD_Espec_CONCAT.xlsx' df_geral.to_excel(output_geral, index=False, engine='openpyxl') df_espec.drop(columns=['Dias de Dura\u00e7\u00e3o Float'], inplace=True) df_espec.to_excel(output_espec, index=False, engine='openpyxl') return output_geral, output_espec","title":"generate_project_status"},{"location":"Rotinas/minera%C3%A7%C3%A3oDOs/","text":"pdfReader.py, v3.py e v4.py Objetivo Realizar a extra\u00e7\u00e3o dos decretos relacionados a uma se\u00e7\u00e3o do Di\u00e1rio Oficial do Estado do Rio de Janeiro. As ferramentas de leitura de pdf extraem o texto reduzindo a dimens\u00e3o da informa\u00e7\u00e3o deste de linhas e colunas para apenas uma coluna com cada paragrafo identidicado e suas coordenadas da pagina, assim devido a formata\u00e7\u00e3o do Di\u00e1rio oficial temos erros durante esse redimensionamento causando a necessidade destas rotinas. Para esse fim foi reazlizado o desenvolvimento de duas maneiras diferentes de se extrair as informa\u00e7\u00f5es desejadas. A primeira foi pdfReader onde primeiro tentamos identificar a qual tipo de coluna o par\u00e1grafo lido pertence para depois verificar se sua posi\u00e7\u00e3o no documento esta correta ou n\u00e3o. A segunda foi v4.py que funciona de maneira mais simples a custo de ter v\u00e1rias passagens por pagina do documento. O desenvolvimento de ambas as fun\u00e7\u00f5es foi interrompido devido a poss\u00edvel disponibiliza\u00e7\u00e3o do banco de dados da Secret\u00e1ria de Estado da Casa C\u00edvil e extens\u00e3o do prazo final do PDA(Plano de Dados Abertos) do dia 06/06/2025 para 06/09/2025. pdfReader.py e v3.py v4.py pdfReader.py e v3.py Status Em desenvolvimento. Funcionamento Ambos os c\u00f3digos tem as mesmas rotinas, mas durante o desenvolvimento da vers\u00e3o parametrizada( pdfReader.py ) houve a necessidade de se expandir o escopo, assim surgiu v3.py cujo funcionamento \u00e9 identico ao seu antecessor mas sem a necessidade dos par\u00e2metros identificadores. Assim ambos est\u00e3o sendo explicados na mesma se\u00e7\u00e3o. O desenvolvimento foi interrompido antes da resolu\u00e7\u00e3o dos seguintes problemas: alta especificidade do c\u00f3digo (Teria que mapear todas as possibilidades de arranjo das colunas no Di\u00e1rio Oficial). Adicionar os casos de erro faltante no processo de identifica\u00e7\u00e3o. A seguir a explica\u00e7\u00e3o de sua rotina. Para o funcionamento desta rotina s\u00e3o necess\u00e1rias as seguintes bibliotecas: import re import json import tqdm import pymupdf A rotina se baseia em recuperar os Atos Oficiais presentes no Di\u00e1rio Oficial(DO), separando por seus \"Ids\" a fim de utilizarmo-os para aplica\u00e7\u00f5es futuras. Ela apresenta 1 rotina principal divida em 3 partes, sendo 2 delas subrotinas. #Chamada Principal retirar(CAMINHOPARAODO, VERBOSE) A rotina \u00e9 constituida de 3 Fun\u00e7\u00f5es: Recupera\u00e7\u00e3o e arruma\u00e7\u00e3o dos blocos do documento Defini\u00e7\u00e3o de colunas Checagem das colunas Abaixo explicaremos cada uma delas de maneira detalhada. Fun\u00e7\u00f5es retirar def retirar(filepath, verbose=False) A fun\u00e7\u00e3o retirar \u00e9 a fun\u00e7\u00e3o principal de pdfReader.py , nela \u00e9 realizado toda a l\u00f3gica de retirada e tratamento do texto do DO com aux\u00edlio das fun\u00e7\u00f5es defColunas e sortColunas . \u00c9 de responsabilidade da fun\u00e7\u00e3o retirar a retirada do texto contido no pdf do DO, a separa\u00e7\u00e3o das linhas irrelevantes daquelas interessantes e o particionamento dos Atos Oficiais por seus \"Ids\". Ela recebe 2 argumentos, o primeiro filepath \u00e9 o caminho para o arquivo pdf a ser lido e o segundo verbose serve para habilitar a impress\u00e3o das etapas a fim de realiza\u00e7\u00e3o de corre\u00e7\u00f5es no c\u00f3digo, este \u00faltimo tem valor False como padr\u00e3o. nomeDir = \"DOsProcessados/Decretos/\"+filepath.split(\"/\")[-1].split(\".\")[0] if not os.path.isdir(\"DOsProcessados\"): os.mkdir(\"DOsProcessados\") os.mkdir(\"DOsProcessados/Decretos\") os.mkdir(nomeDir) elif not os.path.isdir(nomeDir): os.mkdir(nomeDir) doc = pdf.open(filepath) arq = [] for i in doc: for j in i.get_text(\"blocks\"): arq.append(j) achei = False pattern = r'(\\\\x[01][0-9A-Fa-f]|\\\\ufffd)' ## remover caracteres binarios do documento par = 0 pagina = 0 acc = [] paragrafo= \"\" valor = False for lines in tqdm.tqdm(range(len(arq))): if par < arq[lines][-2]: par = arq[lines][-2] else: par = arq[lines][-2] pagina+=1 if (pagina == 1 and arq[lines][-2]<19) or (pagina == 2 and arq[lines][-2]<18) or (arq[lines][4]==\"\") or (len(arq[lines][4])<=2): continue if \"\".join(arq[lines][4].split(\"\\n\")) in [\"Solicite seu or\\u00e7amento: \", \"Decreto Estadual 47.364/2020\", \"OBRIGATORIEDADE DE CONSULTA \\u00c0 IMPRENSA OFI-CIAL NAS CONTRATA\\u00c7\\u00d5ES DE SERVI\\u00c7OS GR\\u00c1FI-COS PELA ADMINISTRA\\u00c7\\u00c3O DIRETA E INDIRETA.\", \"2,00R$\", \"Livrosnovosde\", \"at\\u00e9 9,00\", \"programamaisleitura\", \"maisleitura@ioerj.rj.gov.br\", \"Ler \\u00e9 o maior barato!\", \"programamaisleituramaisleitura@ioerj.rj.gov.br\", \" acesso \\u00e0 leitura.acesso \\u00e0 leitura.\", \"Endere\\u00e7os\"]: continue if re.search(pattern,arq[lines][4].encode(\"unicode_escape\").decode()): continue if \"O VALOR DA\\nSEGURAN\u00c7A\" in arq[lines][4]: fraseSem = \"\" booleanValor = False for frase in arq[lines][4].split(\"\\n\"): if frase != \"O VALOR DA\" and not booleanValor: fraseSem += frase + \"\\n\" elif frase == \"O VALOR DA\" or booleanValor: booleanValor = True paragrafo += frase aux = list(arq[lines]) aux[4]=fraseSem aux[-1] = pagina acc.append(tuple(aux)) valor = True continue elif valor: if acc == \"O VALOR DASEGURAN\u00c7APUBLICOUNAIMPRENSA,\u00c9OFICIAL\": valor = False paragrafo = \"\" else: paragrafo+=arq[lines][4].split(\"\\n\")[0] if re.search(r'ATOS DO PODER EXECUTIVO\\n', arq[lines][4]): achei = True if re.search(r'Despachos do Governador\\n', arq[lines][4]) or re.search(r'Secretaria de Estado da Casa Civil\\n', arq[lines][4]): achei = False break elif achei: aux = list(arq[lines]) aux[-1] = pagina acc.append(tuple(aux)) A primeira parte do c\u00f3digo \u00e9 respons\u00e1vel pela filtragem dos par\u00e1grafos irrelevantes do documento, ele procura no texto par\u00e1grafos chave que s\u00e3o repetidos em imagens, tabelas e outros itens irrelevantes para nosso processamento e retira-os a fim de evitar a polui\u00e7\u00e3o do texto do Atos, al\u00e9m de guardar a p\u00e1gina em que o par\u00e1grafo se encontra j\u00e1 que esse contexto \u00e9 perdido durante a leitura. O pymupdf realiza a leitura do pdf e retorna tuplas com a seguinte postura: [ x0 , y0, x1, y1 , PARAGRAFOLIDO, NUMPARAGRAFOPAG, TIPO] , onde x0 e y0 s\u00e3o os pontos de in\u00edcio do par\u00e1grafo, x1, y1 s\u00e3o os pontos finais, PARAGRAFOLIDO \u00e9 o texto bruto do Ato e NUMPARAGRAFOPAG \u00e9 o n\u00famero de aparecimento do par\u00e1grafo na p\u00e1gina, salvamos essa informa\u00e7\u00e3o em uma vari\u00e1vel chamada arq . Ap\u00f3s o salvamento, percorremos arq procurando os par\u00e1grafos a serem eliminados e sobrescrevendo a vari\u00e1vel TIPO com a p\u00e1gina ao qual o par\u00e1grafo pertence. acumulador = \"\" ultimo = \"\" colunas = defColunas(acc) colunas = sortColunas(colunas,\"ATOS DO PODER EXECUTIVO\\n\") procurar = True for i in colunas: if i[2][4] != \"ATOS DO PODER EXECUTIVO\\n\" and procurar: print(i[2]) continue procurar = False aux = re.search(r'Id: [0-9]*\\n?', i[2][4]) if aux : if len(i[2][4])> aux.span()[1]: acumulador+=i[2][4][0:aux.span()[1]] out = open(nomeDir+\"/\"+i[2][4][aux.span()[0]+3:aux.span()[1]].rstrip(\"\\n\")+\".txt\", \"wb\") out.write(acumulador.encode(\"utf-8\")) out.close() acumulador = i[2][4][aux.span()[1]:] else: acumulador += i[2][4] out = open(nomeDir+\"/\"+i[2][4][aux.span()[0]+3:aux.span()[1]].lstrip(\" \").rstrip(\"\\n\")+\".txt\", \"wb\") out.write(acumulador.encode(\"utf-8\")) acumulador = \"\" else: acumulador+=i[2][4] Na segunda parte do c\u00f3digo temos a utiliza\u00e7\u00e3o das fun\u00e7\u00f5es defColuns e sortColuns , elas realizam as rotinas de defini\u00e7\u00e3o do tipo de coluna sendo utilizado pelo par\u00e1grafo e ordena\u00e7\u00e3o dos par\u00e1grafos de acordo com as coordenadas respectivamente, explicaremos o funcionamento de cada uma dessas fun\u00e7\u00f5es mais adiante no documento. Ap\u00f3s o retorno destas fun\u00e7\u00f5es realizamos a separa\u00e7\u00e3o dos Atos, essa separa\u00e7\u00e3o \u00e9 feita primeiro ignorando tudo aquilo identificado como sendo antecedente ao t\u00edtulo Atos do Poder Executivo e em seguida acumulando os par\u00e1grafos restantes at\u00e9 encontrarmos um \"Id\", parte onde salvamos todos esses acumulados em um arquivo de nome igual ao \"Id\" do ato. defColunas A fun\u00e7\u00e3o defColunas tem como objetivo identificar a qual tipo de coluna o par\u00e1grafo pertence. Essa categoriza\u00e7\u00e3o \u00e9 feita utilizando os par\u00e2metros presentes na tupla salva em arq , retornando uma nova tupla do estilo [ TIPO, METRICAS, TUPLAORIGINAL ] onde TIPO \u00e9 a classifica\u00e7\u00e3o da coluna, METRICAS s\u00e3o as m\u00e9tricas do par\u00e1grafo, sendo elas [ TAMANHO, CENTRO, y0 e y1 ] onde o TAMANHO \u00e9 a largura do par\u00e1grafo, CENTRO \u00e9 onde o paragrafo esta centrado e y0, y1 s\u00e3o o ponto de inicio e final da altura do paragrafo, e TUPLAORIGINAL \u00e9 a tupla anteriormente salva em arq . Ele recebe 2 par\u00e2metros de entrada, o array a ser classificado e o verbose para habilitar a impress\u00e3o dos debugs. def defColunas(paragrafos, verbose=False): import re colunas = [[0,[],()] for _ in range(len(paragrafos))] # 1 = coluna 1/3 # 2 = coluna 2/3 # 3 = coluna 3/3 # 4 = coluna 1/2 # 5 = coluna 2/2 # 6 = coluna 1/1 # 9 = id coluna 3/3 #10 = coluna 1 2/3 #11 = coluna 2 2/3 def metricas(tupla): return [ tupla[2]-tupla[0], (tupla[2]-tupla[0])/2 + tupla[0], tupla[1], tupla[3]] colunaUnica=False anexo = 0 for i in range(len(paragrafos)): colunas[i][1] = metricas(paragrafos[i]) colunas[i][2] = paragrafos[i] regex = re.search(r'ANEXO ?([IVXL]+|\\u00daNICO?|.*)', paragrafos[i][4]) if regex and regex.span()[0] == 0: anexo+=1 if colunas[i][1][0] >341 and not re.search(r'Id: [0-9]*\\n?', paragrafos[i][4]): if colunas[i][1][1] < 480: colunaUnica = True colunas[i][0] = 6 else: colunas[i][0] = 11 elif colunas[i][1][0]>228 and not re.search(r'Id: [0-9]*\\n?', paragrafos[i][4]): if paragrafos[i][0] > 400: colunas[i][0] = 5 if colunas[i][1][1] > 530 else 11 else: colunas[i][0] = 4 A primeira parte do c\u00f3digo trata daqueles par\u00e1grafos com grande largura, j\u00e1 que apenas alguns possuem essa caracter\u00edstica. observamos a largura do par\u00e1grafo( colunas[i][1][0] ) e sua centralidade( colunas[i][1][0] ) assim conseguimos separar os par\u00e1grafos de coluna \u00fanica(6), de duas colunas(4 e 5) por p\u00e1gina ou colunas de extens\u00e3o duplas(10 e 11) tamb\u00e9m nesse \u00faltimo caso de qual lado est\u00e1 o par\u00e1grafo. else: if re.search(r'Id: [0-9]*\\n?', paragrafos[i][4]): if colunas[i][1][1] < 279: colunas[i][0] = 1 elif colunas[i][1][1] < 520 and colunas[i][1][0]<228: if 400<paragrafos[i][2]<488: colunas[i][0] = 10 k=1 while i-k > 0 and anexo > 0: colunas[i-k][0] = 10 regex = re.search(r'ANEXO ?([IVXL]+|\\u00daNICO?|.*)', paragrafos[i-k][4]) if (regex and regex.span()[0]==0 ): anexo-=1 k+=1 colunaUnica = False if paragrafos[i][2]<400: colunas[i][0] = 4 k=1 while i-k > 0 and anexo > 0: colunas[i-k][0] = 4 regex = re.search(r'ANEXO ?([IVXL]+|\\u00daNICO?|.*)', paragrafos[i-k][4]) if (regex and regex.span()[0]==0 ): anexo-=1 k+=1 colunaUnica = False else: colunas[i][0] = 2 else: if colunaUnica : colunas[i][0] = 6 else: colunas[i][0] = colunas[i-1][0] k=1 while i-k > 0 and anexo > 0 : if colunaUnica: colunas[i-k][0] = 6 regex = re.search(r'ANEXO ?([IVXL]+|\\u00daNICO?|.*)', paragrafos[i-k][4]) if (regex and regex.span()[0]==0): anexo-=1 k+=1 colunaUnica = False elif not re.search(r'C *O *N *S *I *D *E *R *A *N *D *O *:|R *E *S *O *L *V *E *:|D *E *C *R *E *T *A *:', paragrafos[i][4]): if abs(colunas[i][1][1] - 222.655632019043) < 125 and paragrafos[i][2] > 280: colunas[i][0] = 4 elif 534 > paragrafos[i][0] > 420 : colunas[i][0] = 5 elif 279 < colunas[i][1][1] < 480 : colunas[i][0] = 2 elif colunas[i][1][1] < 279 and (abs(colunas[i][1][1] - 222.655632019043) > abs(colunas[i][1][1] - 165.8691997528076) or (0 < 122.3 - paragrafos[i][0] < 0.2 and 0 < 280 - paragrafos[i][2] < 1 )): colunas[i][0] = 1 elif colunas[i][1][1] < 279 and abs(colunas[i][1][1] - 222.655632019043) < abs(colunas[i][1][1] - 165.8691997528076): colunas[i][0] = 4 elif colunas[i][1][1] > 420 and (abs(colunas[i][1][1] - 590.9314880371094) > abs(colunas[i][1][1] - 647.7062683105469) or 0 < 534.4 - paragrafos[i][0] < 0.8): colunas[i][0] = 3 elif colunas[i][1][1] > 420 and (abs(colunas[i][1][1] - 590.9314880371094) < abs(colunas[i][1][1] - 647.7062683105469)): colunas[i][0] = 5 elif re.search(r'C *O *N *S *I *D *E *R *A *N *D *O *:|R *E *S *O *L *V *E *:|D *E *C *R *E *T *A *:', paragrafos[i][4]): if 0 < 293.5 - paragrafos[i][0] < 0.15: colunas[i][0] = 2 elif 0 < 534.4 - paragrafos[i][0] < 0.8: colunas[i][0] = 3 else: colunas[i][0] = colunas[i-1][0] if verbose: for i in range(len(paragrafos)): print(colunas[i]) return colunas O caso dos par\u00e1grafos pequenos apresenta maior dificuldade de classifica\u00e7\u00e3o uma vez que par\u00e1grafos de tipos diferentes podem acabar ocupando o mesmo espa\u00e7o, assim para definirmos sua classifica\u00e7\u00e3o devemos olhar aqueles que vem antes e/ou depois. O primeiro caso analizado \u00e9 se h\u00e1 a presen\u00e7a do \"Id\" no paragrafo, assim podemos definir o tipo dele observando sua centralidade e posi\u00e7\u00e3o de quem vem antes. Em seguida observamos mais atentamente os par\u00e2metros existentes a fim de definir a coluna. Uma vez terminada a analize retornamos todas as m\u00e9tricas calculadas. sortColunas A fun\u00e7\u00e3o sortColunas tem como objetivo arrumar os paragrafos na ordem de leitura correto, assim garantindo sua corretude. Ela recebe 3 par\u00e2metros de entrada, sendo eles o array a ser arrumado, o t\u00edtulo da se\u00e7\u00e3o sendo analizada e verbose para impress\u00e3o em tela. Seu funcionamento ocorre ao percorrermos o array passado, observando se seus membros obedecem as regras abaixo: Se eu estou na mesma p\u00e1gina, n\u00e3o posso subir na mesma coluna Se eu estou na mesma p\u00e1gina, n\u00e3o posso subir para a esquerda outras regras se mostram necessarias para casos mais espec\u00edficos, entretanto essas duas j\u00e1 contemplam boa parte dos erros de formata\u00e7\u00e3o encontrados. def sortColunas(colunas,Titulo, verbose = False): from re import search for i in range(len(colunas)): if i == 0 and colunas[i][2][4] != Titulo: print(colunas[i][2][4],\"O titulo da se\u00e7\u00e3o e o das colunas n\u00e3o batem\") if verbose else \"\" break elif i == 0: colunas[i][0] = colunas[i+1][0] antes = colunas[i-1] agora = colunas[i] depois = colunas[i+1] if i+1 < len(colunas)-1 else \"\" # corrigindo a coluna de alguns que passaram if depois != \"\" and antes[0] == depois[0] and antes[0] != agora[0] and antes[1][-1]<agora[1][-2]<depois[1][-2]: print(cores[\"ciano\"]+\"\\nConfundi Coluna: \"+cores[\"reset\"], antes[0],agora[0], depois[0]) if verbose else \"\" agora[0] = antes[0] input() if verbose else \"\" # Corrigindo coluna unica if depois != \"\" and depois[0] == 6 and agora[0] in [1,2,4,10] and not search(r'ANEXO ?([IVXL]+|\\u00daNICO?|.*)', depois[2][4]): print(cores[\"amarelo\"]+\"Achei coluna unica: \"+cores[\"reset\"]) if verbose else \"\" k=0 abaixo = depois while i-k>=0 and not (search(r'DECRETO', colunas[i-k][2][4]) and search(r'DECRETO', colunas[i-k][2][4]).span()[0] == 0) and colunas[i-k][0] in [1,2,4,10] and colunas[i-k][1][-1]<abaixo[1][-2] and abaixo[2][-1] == colunas[i-k][2][-1]: colunas[i-k][0] = 6 abaixo = colunas[i-k] k+=1 colunas[i-k][0] = 6 agora = colunas[i] print(colunas[i-k]) if verbose else \"\" print(colunas[i-k+1]) if verbose else \"\" print(\"parei em \", colunas[i-k], \"\\n\") if verbose else \"\" input() if verbose else \"\" # se em mesma pagina if agora[2][-1] == antes[2][-1]: # se eu estou acima do meu antecessor if agora[1][-2]<antes[1][-1]: # se estou na mesma coluna que meu antecessor if agora[0] == antes[0] : print(cores[\"azul\"] + \"\\nMesma coluna Errado:\" + cores[\"reset\"],agora[0], agora[1][-2], antes[1][-1]) if verbose else \"\" k=1 while i-k >= 0 and agora[1][-2] < colunas[i-k][1][-1] and agora[0] == colunas[i-k][0] and agora[2][-1] == colunas[i-k][2][-1] : k+=1 print(\"Botei antes de\", i-k+1, colunas[i-k][0:2]) if verbose else \"\" aux = colunas.pop(i) colunas.insert(i-k+1, aux) print(colunas[i-k][0:2]) if verbose else \"\" print(colunas[i-k+1][0:2]) if verbose else \"\" print(colunas[i-k+2][0:2]) if verbose else \"\" input() if verbose else \"\" # se estou em uma coluna antes do meu antecessor elif agora[0]<antes[0]: print(\"\\033[2J\\033[H\", end='') if verbose else \"\" for a in range(i): print(colunas[a]) if verbose else \"\" print(cores[\"verde\"] + \"\\ndiferentes coluna Errado:\" + cores[\"reset\"] , agora[0:2], antes[0:2]) if verbose else \"\" k=1 while i-k>=0 and (agora[2][-1] == colunas[i-k][2][-1]): if (agora[0] == colunas[i-k][0] and agora[1][-2] > colunas[i-k][1][-1]) or (colunas[i-k][0] < agora[0]): break k+=1 print(\"Botei antes de\", i-k, colunas[i-k][0:2]) if verbose else \"\" aux = colunas.pop(i) colunas.insert(i-k+1, aux) print(colunas[i-k][0:2]) if verbose else \"\" print(colunas[i-k+1][0:2]) if verbose else \"\" print(colunas[i-k+2][0:2]) if verbose else \"\" input() if verbose else \"\" if verbose: for i in range(len(colunas)): print(colunas[i]) return colunas v4.py Status Em desenvolvimento Funcionamento Essa rotina funciona ao tentar arrumar o texto extra\u00eddo do pdf de maneira gulosa para cada par\u00e1grafo. Sua l\u00f3gica funciona de maneira a para cada par\u00e1grafo( pivot ) olha para frente e busca frases cujo as coordenadas indicam: que sou da mesma coluna que o pivot que sou acima do pivot E com isso identificamos os par\u00e1grafos onde a estra\u00e7\u00e3o foi mal realizada. A identifica\u00e7\u00e3o da coluna acontece ao medirmos se h\u00e1 interse\u00e7\u00e3o entre a ar\u00e9a ocupada na dimens\u00e3o X do pivot com a da frase analizada. Isso funciona devido ao fato da arruma\u00e7\u00e3o em colunas se dar separados por margens, assim toda coluna apresenta intesess\u00e3o entre seus paragrafos em rela\u00e7\u00e3o ao eixo X. O problema apenas se da na forma de que o minerador do pdf retira as informa\u00e7\u00f5es, se prendendo apenas ao tamanho da frase em si em vez de ocupar o tamanho da coluna toda. O desenvolvimento foi interrompido antes da solu\u00e7\u00e3o das seguintes quest\u00f5es: Identifica\u00e7\u00e3o dos limites da coluna: O pivot pode estar na mesma coluna da frase e n\u00e3o ser grande o suficiente para englobar a outra frase, caso dos T\u00edtulo com o ID. N\u00e3o acredito que preciso realizar esse c\u00e1lculo previamente, apenas olhando os casos na hora deve ser suficiente. Abaixo a explica\u00e7\u00e3o de sua rotina. Ela se utiliza das seguintes bibliotecas: import os import tqdm import json import re import pymupdf as pdf Temos dois m\u00e9todos de apoio cujo funcionamento se assemelham, infringeSemiEspaco e infringeEspaco . Ambas testam pra ver se h\u00e1 interse\u00e7\u00e3o, sendo que a primeira parcial, isto \u00e9, se temos pelo menos um v\u00e9rtice de algum deles dentro da \u00e1rea do outro, e a segunda total, ambas os v\u00e9rtices dentro da \u00e1rea do outro. def infringeSemiEspaco(e1, e2,indice = 0): maior = e1 if e1[indice+2] - e1[indice] > e2[indice+2] - e2[indice] else e2 if (maior == e1 and ( maior[indice]<=e2[indice]<=maior[indice+2] or maior[indice]<=e2[indice+2]<=maior[indice+2])) or (maior == e2 and ( maior[indice]<=e1[indice]<=maior[indice+2] or maior[indice]<=e1[indice+2]<=maior[indice+2])): return True else: return False def infringeEspaco(e1, e2,indice = 0): maior = e1 if e1[indice+2] - e1[indice] > e2[indice+2] - e2[indice] else e2 if (maior == e1 and ( maior[indice]<=e2[indice]<=maior[indice+2] and maior[indice]<=e2[indice+2]<=maior[indice+2])) or (maior == e2 and ( maior[indice]<=e1[indice]<=maior[indice+2] and maior[indice]<=e1[indice+2]<=maior[indice+2])): return True else: return False A rotina principal tem funcionamento ideintico \u00e0 v3/pdfReader retirando algumas linhas que s\u00e3o consideradas in\u00fateis, como aquelas de propaganda/c\u00f3digos de formata\u00e7\u00e3o que n\u00e3o carregam nenhuma informa\u00e7\u00e3o sobre os decretos, depois separamos cada par\u00e1grafo por p\u00e1gina e come\u00e7amos a procurar os par\u00e1grafos fora de ordem. Essa procura \u00e9 feita olhando para cada par\u00e1grafo se algu\u00e9m abaixo dele, deveria estar acima dele. Fazemos essa procura por causa da l\u00f3gica de leitura e perda de dimensionalidade trazida pelo leitor de PDF, com isso aqueles par\u00e1grafos que se encontram fora de lugar acabam por se encontrarem em um ponto \u00e0 frente de algum de seus colegas de colunas. def retirar(filepath, verbose = False): import re import pymupdf as pdf limites = [52.441368103027344, 87.45538330078125, 761.1741333007812, 1180.38134765625] nomeDir = \"DOsProcessados/Decretos/\"+filepath.split(\"/\")[-1].split(\".\")[0] if not os.path.isdir(\"DOsProcessados\"): os.mkdir(\"DOsProcessados\") os.mkdir(\"DOsProcessados/Decretos\") os.mkdir(nomeDir) elif not os.path.isdir(nomeDir): os.mkdir(nomeDir) doc = pdf.open(filepath) arq = [] for i in doc: pagina = [] for j in i.get_text(\"blocks\"): pagina.append(j) arq.append(pagina) pattern = r'(\\\\x[01][0-9A-Fa-f]|\\\\ufffd)' ## remover caracteres binarios do documento par = 0 pagina = 0 do = [] paragrafo= \"\" valor = False contador = 0 for page in tqdm.tqdm(arq): acc = [] for lines in range(len(page)): if par < page[lines][-2]: par = page[lines][-2] else: par = page[lines][-2] pagina+=1 if (pagina == 1 and page[lines][-2]<19) or (pagina == 2 and page[lines][-2]<18) or (page[lines][4]==\"\") or (len(page[lines][4])<=2): if re.search(r'Id: [0-9]+', page[lines][4]): print('foi aqui 1') if re.search(r'SEI-080002/002420/2024',page[lines][4]): print(page[lines][4]) continue if \"\".join(page[lines][4].split(\"\\n\")) in [\"FI\",\"Solicite seu or\\u00e7amento: \", \"Decreto Estadual 47.364/2020\", \"OBRIGATORIEDADE DE CONSULTA \\u00c0 IMPRENSA OFI-CIAL NAS CONTRATA\\u00c7\\u00d5ES DE SERVI\\u00c7OS GR\\u00c1FI-COS PELA ADMINISTRA\\u00c7\\u00c3O DIRETA E INDIRETA.\", \"2,00R$\", \"Livrosnovosde\", \"at\\u00e9 9,00\", \"programamaisleitura\", \"maisleitura@ioerj.rj.gov.br\", \"Ler \\u00e9 o maior barato!\", \"programamaisleituramaisleitura@ioerj.rj.gov.br\", \" acesso \\u00e0 leitura.acesso \\u00e0 leitura.\", \"Endere\\u00e7os\"]: if re.search(r'Id: [0-9]+', page[lines][4]): print('foi aqui 2') if re.search(r'SEI-080002/002420/2024',page[lines][4]): print(page[lines][4]) continue if re.search(pattern,page[lines][4].encode(\"unicode_escape\").decode()): if re.search(r'Id: [0-9]+', page[lines][4]): print('foi aqui 3') if re.search(r'SEI-080002/002420/2024',page[lines][4]): print(page[lines][4]) continue if \"O VALOR DA\\nSEGURAN\u00c7A\" in page[lines][4]: fraseSem = \"\" booleanValor = False for frase in page[lines][4].split(\"\\n\"): if frase != \"O VALOR DA\" and not booleanValor: fraseSem += frase + \"\\n\" elif frase == \"O VALOR DA\" or booleanValor: booleanValor = True paragrafo += frase aux = list(page[lines]) aux[4]=fraseSem aux[-1] = pagina if re.search(r'Id: [0-9]+', page[lines][4]): print('foi aqui 4') print(len(acc), lines) acc.append(tuple(aux)) valor = True continue elif valor: if acc == \"O VALOR DASEGURAN\u00c7APUBLICOUNAIMPRENSA,\u00c9OFICIAL\": valor = False paragrafo = \"\" else: paragrafo+=page[lines][4].split(\"\\n\")[0] aux = list(page[lines]) aux[-1] = pagina acc.append(tuple(aux)) else: if re.search(r'SEI-080002/002420/2024',page[lines][4]): print(\"AQUIIIIIIIIIIII\") print(page[lines][4]) print(len(acc),lines) aux = list(page[lines]) aux[-1] = pagina acc.append(tuple(aux)) do.append(acc) for pagina2 in range(len(do)): blocos = [] tamanhoPagina = len(do[pagina2]) paragrafo2 = 0 while paragrafo2 < tamanhoPagina: for depois in range(paragrafo2+1,tamanhoPagina): if(do[pagina2][paragrafo2][3] > do[pagina2][depois][3] and infringeEspaco(do[pagina2][paragrafo2], do[pagina2][depois])): for antes in range(0, paragrafo2): if(do[pagina2][depois][3] < do[pagina2][antes][3] and infringeEspaco(do[pagina2][depois], do[pagina2][antes])): print(\"ACHEI\", pagina2) print(do[pagina2][paragrafo2]) print(do[pagina2][depois]) print(do[pagina2][antes]) print() input() paragrafo2 +=1","title":"pdfReader.py, v3.py e v4.py"},{"location":"Rotinas/minera%C3%A7%C3%A3oDOs/#pdfreaderpy-v3py-e-v4py","text":"","title":"pdfReader.py, v3.py e v4.py"},{"location":"Rotinas/minera%C3%A7%C3%A3oDOs/#objetivo","text":"Realizar a extra\u00e7\u00e3o dos decretos relacionados a uma se\u00e7\u00e3o do Di\u00e1rio Oficial do Estado do Rio de Janeiro. As ferramentas de leitura de pdf extraem o texto reduzindo a dimens\u00e3o da informa\u00e7\u00e3o deste de linhas e colunas para apenas uma coluna com cada paragrafo identidicado e suas coordenadas da pagina, assim devido a formata\u00e7\u00e3o do Di\u00e1rio oficial temos erros durante esse redimensionamento causando a necessidade destas rotinas. Para esse fim foi reazlizado o desenvolvimento de duas maneiras diferentes de se extrair as informa\u00e7\u00f5es desejadas. A primeira foi pdfReader onde primeiro tentamos identificar a qual tipo de coluna o par\u00e1grafo lido pertence para depois verificar se sua posi\u00e7\u00e3o no documento esta correta ou n\u00e3o. A segunda foi v4.py que funciona de maneira mais simples a custo de ter v\u00e1rias passagens por pagina do documento. O desenvolvimento de ambas as fun\u00e7\u00f5es foi interrompido devido a poss\u00edvel disponibiliza\u00e7\u00e3o do banco de dados da Secret\u00e1ria de Estado da Casa C\u00edvil e extens\u00e3o do prazo final do PDA(Plano de Dados Abertos) do dia 06/06/2025 para 06/09/2025. pdfReader.py e v3.py v4.py","title":"Objetivo"},{"location":"Rotinas/minera%C3%A7%C3%A3oDOs/#pdfreaderpy-e-v3py","text":"","title":"pdfReader.py e v3.py"},{"location":"Rotinas/minera%C3%A7%C3%A3oDOs/#status","text":"Em desenvolvimento.","title":"Status"},{"location":"Rotinas/minera%C3%A7%C3%A3oDOs/#funcionamento","text":"Ambos os c\u00f3digos tem as mesmas rotinas, mas durante o desenvolvimento da vers\u00e3o parametrizada( pdfReader.py ) houve a necessidade de se expandir o escopo, assim surgiu v3.py cujo funcionamento \u00e9 identico ao seu antecessor mas sem a necessidade dos par\u00e2metros identificadores. Assim ambos est\u00e3o sendo explicados na mesma se\u00e7\u00e3o. O desenvolvimento foi interrompido antes da resolu\u00e7\u00e3o dos seguintes problemas: alta especificidade do c\u00f3digo (Teria que mapear todas as possibilidades de arranjo das colunas no Di\u00e1rio Oficial). Adicionar os casos de erro faltante no processo de identifica\u00e7\u00e3o. A seguir a explica\u00e7\u00e3o de sua rotina. Para o funcionamento desta rotina s\u00e3o necess\u00e1rias as seguintes bibliotecas: import re import json import tqdm import pymupdf A rotina se baseia em recuperar os Atos Oficiais presentes no Di\u00e1rio Oficial(DO), separando por seus \"Ids\" a fim de utilizarmo-os para aplica\u00e7\u00f5es futuras. Ela apresenta 1 rotina principal divida em 3 partes, sendo 2 delas subrotinas. #Chamada Principal retirar(CAMINHOPARAODO, VERBOSE) A rotina \u00e9 constituida de 3 Fun\u00e7\u00f5es: Recupera\u00e7\u00e3o e arruma\u00e7\u00e3o dos blocos do documento Defini\u00e7\u00e3o de colunas Checagem das colunas Abaixo explicaremos cada uma delas de maneira detalhada.","title":"Funcionamento"},{"location":"Rotinas/minera%C3%A7%C3%A3oDOs/#funcoes","text":"","title":"Fun\u00e7\u00f5es"},{"location":"Rotinas/minera%C3%A7%C3%A3oDOs/#retirar","text":"def retirar(filepath, verbose=False) A fun\u00e7\u00e3o retirar \u00e9 a fun\u00e7\u00e3o principal de pdfReader.py , nela \u00e9 realizado toda a l\u00f3gica de retirada e tratamento do texto do DO com aux\u00edlio das fun\u00e7\u00f5es defColunas e sortColunas . \u00c9 de responsabilidade da fun\u00e7\u00e3o retirar a retirada do texto contido no pdf do DO, a separa\u00e7\u00e3o das linhas irrelevantes daquelas interessantes e o particionamento dos Atos Oficiais por seus \"Ids\". Ela recebe 2 argumentos, o primeiro filepath \u00e9 o caminho para o arquivo pdf a ser lido e o segundo verbose serve para habilitar a impress\u00e3o das etapas a fim de realiza\u00e7\u00e3o de corre\u00e7\u00f5es no c\u00f3digo, este \u00faltimo tem valor False como padr\u00e3o. nomeDir = \"DOsProcessados/Decretos/\"+filepath.split(\"/\")[-1].split(\".\")[0] if not os.path.isdir(\"DOsProcessados\"): os.mkdir(\"DOsProcessados\") os.mkdir(\"DOsProcessados/Decretos\") os.mkdir(nomeDir) elif not os.path.isdir(nomeDir): os.mkdir(nomeDir) doc = pdf.open(filepath) arq = [] for i in doc: for j in i.get_text(\"blocks\"): arq.append(j) achei = False pattern = r'(\\\\x[01][0-9A-Fa-f]|\\\\ufffd)' ## remover caracteres binarios do documento par = 0 pagina = 0 acc = [] paragrafo= \"\" valor = False for lines in tqdm.tqdm(range(len(arq))): if par < arq[lines][-2]: par = arq[lines][-2] else: par = arq[lines][-2] pagina+=1 if (pagina == 1 and arq[lines][-2]<19) or (pagina == 2 and arq[lines][-2]<18) or (arq[lines][4]==\"\") or (len(arq[lines][4])<=2): continue if \"\".join(arq[lines][4].split(\"\\n\")) in [\"Solicite seu or\\u00e7amento: \", \"Decreto Estadual 47.364/2020\", \"OBRIGATORIEDADE DE CONSULTA \\u00c0 IMPRENSA OFI-CIAL NAS CONTRATA\\u00c7\\u00d5ES DE SERVI\\u00c7OS GR\\u00c1FI-COS PELA ADMINISTRA\\u00c7\\u00c3O DIRETA E INDIRETA.\", \"2,00R$\", \"Livrosnovosde\", \"at\\u00e9 9,00\", \"programamaisleitura\", \"maisleitura@ioerj.rj.gov.br\", \"Ler \\u00e9 o maior barato!\", \"programamaisleituramaisleitura@ioerj.rj.gov.br\", \" acesso \\u00e0 leitura.acesso \\u00e0 leitura.\", \"Endere\\u00e7os\"]: continue if re.search(pattern,arq[lines][4].encode(\"unicode_escape\").decode()): continue if \"O VALOR DA\\nSEGURAN\u00c7A\" in arq[lines][4]: fraseSem = \"\" booleanValor = False for frase in arq[lines][4].split(\"\\n\"): if frase != \"O VALOR DA\" and not booleanValor: fraseSem += frase + \"\\n\" elif frase == \"O VALOR DA\" or booleanValor: booleanValor = True paragrafo += frase aux = list(arq[lines]) aux[4]=fraseSem aux[-1] = pagina acc.append(tuple(aux)) valor = True continue elif valor: if acc == \"O VALOR DASEGURAN\u00c7APUBLICOUNAIMPRENSA,\u00c9OFICIAL\": valor = False paragrafo = \"\" else: paragrafo+=arq[lines][4].split(\"\\n\")[0] if re.search(r'ATOS DO PODER EXECUTIVO\\n', arq[lines][4]): achei = True if re.search(r'Despachos do Governador\\n', arq[lines][4]) or re.search(r'Secretaria de Estado da Casa Civil\\n', arq[lines][4]): achei = False break elif achei: aux = list(arq[lines]) aux[-1] = pagina acc.append(tuple(aux)) A primeira parte do c\u00f3digo \u00e9 respons\u00e1vel pela filtragem dos par\u00e1grafos irrelevantes do documento, ele procura no texto par\u00e1grafos chave que s\u00e3o repetidos em imagens, tabelas e outros itens irrelevantes para nosso processamento e retira-os a fim de evitar a polui\u00e7\u00e3o do texto do Atos, al\u00e9m de guardar a p\u00e1gina em que o par\u00e1grafo se encontra j\u00e1 que esse contexto \u00e9 perdido durante a leitura. O pymupdf realiza a leitura do pdf e retorna tuplas com a seguinte postura: [ x0 , y0, x1, y1 , PARAGRAFOLIDO, NUMPARAGRAFOPAG, TIPO] , onde x0 e y0 s\u00e3o os pontos de in\u00edcio do par\u00e1grafo, x1, y1 s\u00e3o os pontos finais, PARAGRAFOLIDO \u00e9 o texto bruto do Ato e NUMPARAGRAFOPAG \u00e9 o n\u00famero de aparecimento do par\u00e1grafo na p\u00e1gina, salvamos essa informa\u00e7\u00e3o em uma vari\u00e1vel chamada arq . Ap\u00f3s o salvamento, percorremos arq procurando os par\u00e1grafos a serem eliminados e sobrescrevendo a vari\u00e1vel TIPO com a p\u00e1gina ao qual o par\u00e1grafo pertence. acumulador = \"\" ultimo = \"\" colunas = defColunas(acc) colunas = sortColunas(colunas,\"ATOS DO PODER EXECUTIVO\\n\") procurar = True for i in colunas: if i[2][4] != \"ATOS DO PODER EXECUTIVO\\n\" and procurar: print(i[2]) continue procurar = False aux = re.search(r'Id: [0-9]*\\n?', i[2][4]) if aux : if len(i[2][4])> aux.span()[1]: acumulador+=i[2][4][0:aux.span()[1]] out = open(nomeDir+\"/\"+i[2][4][aux.span()[0]+3:aux.span()[1]].rstrip(\"\\n\")+\".txt\", \"wb\") out.write(acumulador.encode(\"utf-8\")) out.close() acumulador = i[2][4][aux.span()[1]:] else: acumulador += i[2][4] out = open(nomeDir+\"/\"+i[2][4][aux.span()[0]+3:aux.span()[1]].lstrip(\" \").rstrip(\"\\n\")+\".txt\", \"wb\") out.write(acumulador.encode(\"utf-8\")) acumulador = \"\" else: acumulador+=i[2][4] Na segunda parte do c\u00f3digo temos a utiliza\u00e7\u00e3o das fun\u00e7\u00f5es defColuns e sortColuns , elas realizam as rotinas de defini\u00e7\u00e3o do tipo de coluna sendo utilizado pelo par\u00e1grafo e ordena\u00e7\u00e3o dos par\u00e1grafos de acordo com as coordenadas respectivamente, explicaremos o funcionamento de cada uma dessas fun\u00e7\u00f5es mais adiante no documento. Ap\u00f3s o retorno destas fun\u00e7\u00f5es realizamos a separa\u00e7\u00e3o dos Atos, essa separa\u00e7\u00e3o \u00e9 feita primeiro ignorando tudo aquilo identificado como sendo antecedente ao t\u00edtulo Atos do Poder Executivo e em seguida acumulando os par\u00e1grafos restantes at\u00e9 encontrarmos um \"Id\", parte onde salvamos todos esses acumulados em um arquivo de nome igual ao \"Id\" do ato.","title":"retirar"},{"location":"Rotinas/minera%C3%A7%C3%A3oDOs/#defcolunas","text":"A fun\u00e7\u00e3o defColunas tem como objetivo identificar a qual tipo de coluna o par\u00e1grafo pertence. Essa categoriza\u00e7\u00e3o \u00e9 feita utilizando os par\u00e2metros presentes na tupla salva em arq , retornando uma nova tupla do estilo [ TIPO, METRICAS, TUPLAORIGINAL ] onde TIPO \u00e9 a classifica\u00e7\u00e3o da coluna, METRICAS s\u00e3o as m\u00e9tricas do par\u00e1grafo, sendo elas [ TAMANHO, CENTRO, y0 e y1 ] onde o TAMANHO \u00e9 a largura do par\u00e1grafo, CENTRO \u00e9 onde o paragrafo esta centrado e y0, y1 s\u00e3o o ponto de inicio e final da altura do paragrafo, e TUPLAORIGINAL \u00e9 a tupla anteriormente salva em arq . Ele recebe 2 par\u00e2metros de entrada, o array a ser classificado e o verbose para habilitar a impress\u00e3o dos debugs. def defColunas(paragrafos, verbose=False): import re colunas = [[0,[],()] for _ in range(len(paragrafos))] # 1 = coluna 1/3 # 2 = coluna 2/3 # 3 = coluna 3/3 # 4 = coluna 1/2 # 5 = coluna 2/2 # 6 = coluna 1/1 # 9 = id coluna 3/3 #10 = coluna 1 2/3 #11 = coluna 2 2/3 def metricas(tupla): return [ tupla[2]-tupla[0], (tupla[2]-tupla[0])/2 + tupla[0], tupla[1], tupla[3]] colunaUnica=False anexo = 0 for i in range(len(paragrafos)): colunas[i][1] = metricas(paragrafos[i]) colunas[i][2] = paragrafos[i] regex = re.search(r'ANEXO ?([IVXL]+|\\u00daNICO?|.*)', paragrafos[i][4]) if regex and regex.span()[0] == 0: anexo+=1 if colunas[i][1][0] >341 and not re.search(r'Id: [0-9]*\\n?', paragrafos[i][4]): if colunas[i][1][1] < 480: colunaUnica = True colunas[i][0] = 6 else: colunas[i][0] = 11 elif colunas[i][1][0]>228 and not re.search(r'Id: [0-9]*\\n?', paragrafos[i][4]): if paragrafos[i][0] > 400: colunas[i][0] = 5 if colunas[i][1][1] > 530 else 11 else: colunas[i][0] = 4 A primeira parte do c\u00f3digo trata daqueles par\u00e1grafos com grande largura, j\u00e1 que apenas alguns possuem essa caracter\u00edstica. observamos a largura do par\u00e1grafo( colunas[i][1][0] ) e sua centralidade( colunas[i][1][0] ) assim conseguimos separar os par\u00e1grafos de coluna \u00fanica(6), de duas colunas(4 e 5) por p\u00e1gina ou colunas de extens\u00e3o duplas(10 e 11) tamb\u00e9m nesse \u00faltimo caso de qual lado est\u00e1 o par\u00e1grafo. else: if re.search(r'Id: [0-9]*\\n?', paragrafos[i][4]): if colunas[i][1][1] < 279: colunas[i][0] = 1 elif colunas[i][1][1] < 520 and colunas[i][1][0]<228: if 400<paragrafos[i][2]<488: colunas[i][0] = 10 k=1 while i-k > 0 and anexo > 0: colunas[i-k][0] = 10 regex = re.search(r'ANEXO ?([IVXL]+|\\u00daNICO?|.*)', paragrafos[i-k][4]) if (regex and regex.span()[0]==0 ): anexo-=1 k+=1 colunaUnica = False if paragrafos[i][2]<400: colunas[i][0] = 4 k=1 while i-k > 0 and anexo > 0: colunas[i-k][0] = 4 regex = re.search(r'ANEXO ?([IVXL]+|\\u00daNICO?|.*)', paragrafos[i-k][4]) if (regex and regex.span()[0]==0 ): anexo-=1 k+=1 colunaUnica = False else: colunas[i][0] = 2 else: if colunaUnica : colunas[i][0] = 6 else: colunas[i][0] = colunas[i-1][0] k=1 while i-k > 0 and anexo > 0 : if colunaUnica: colunas[i-k][0] = 6 regex = re.search(r'ANEXO ?([IVXL]+|\\u00daNICO?|.*)', paragrafos[i-k][4]) if (regex and regex.span()[0]==0): anexo-=1 k+=1 colunaUnica = False elif not re.search(r'C *O *N *S *I *D *E *R *A *N *D *O *:|R *E *S *O *L *V *E *:|D *E *C *R *E *T *A *:', paragrafos[i][4]): if abs(colunas[i][1][1] - 222.655632019043) < 125 and paragrafos[i][2] > 280: colunas[i][0] = 4 elif 534 > paragrafos[i][0] > 420 : colunas[i][0] = 5 elif 279 < colunas[i][1][1] < 480 : colunas[i][0] = 2 elif colunas[i][1][1] < 279 and (abs(colunas[i][1][1] - 222.655632019043) > abs(colunas[i][1][1] - 165.8691997528076) or (0 < 122.3 - paragrafos[i][0] < 0.2 and 0 < 280 - paragrafos[i][2] < 1 )): colunas[i][0] = 1 elif colunas[i][1][1] < 279 and abs(colunas[i][1][1] - 222.655632019043) < abs(colunas[i][1][1] - 165.8691997528076): colunas[i][0] = 4 elif colunas[i][1][1] > 420 and (abs(colunas[i][1][1] - 590.9314880371094) > abs(colunas[i][1][1] - 647.7062683105469) or 0 < 534.4 - paragrafos[i][0] < 0.8): colunas[i][0] = 3 elif colunas[i][1][1] > 420 and (abs(colunas[i][1][1] - 590.9314880371094) < abs(colunas[i][1][1] - 647.7062683105469)): colunas[i][0] = 5 elif re.search(r'C *O *N *S *I *D *E *R *A *N *D *O *:|R *E *S *O *L *V *E *:|D *E *C *R *E *T *A *:', paragrafos[i][4]): if 0 < 293.5 - paragrafos[i][0] < 0.15: colunas[i][0] = 2 elif 0 < 534.4 - paragrafos[i][0] < 0.8: colunas[i][0] = 3 else: colunas[i][0] = colunas[i-1][0] if verbose: for i in range(len(paragrafos)): print(colunas[i]) return colunas O caso dos par\u00e1grafos pequenos apresenta maior dificuldade de classifica\u00e7\u00e3o uma vez que par\u00e1grafos de tipos diferentes podem acabar ocupando o mesmo espa\u00e7o, assim para definirmos sua classifica\u00e7\u00e3o devemos olhar aqueles que vem antes e/ou depois. O primeiro caso analizado \u00e9 se h\u00e1 a presen\u00e7a do \"Id\" no paragrafo, assim podemos definir o tipo dele observando sua centralidade e posi\u00e7\u00e3o de quem vem antes. Em seguida observamos mais atentamente os par\u00e2metros existentes a fim de definir a coluna. Uma vez terminada a analize retornamos todas as m\u00e9tricas calculadas.","title":"defColunas"},{"location":"Rotinas/minera%C3%A7%C3%A3oDOs/#sortcolunas","text":"A fun\u00e7\u00e3o sortColunas tem como objetivo arrumar os paragrafos na ordem de leitura correto, assim garantindo sua corretude. Ela recebe 3 par\u00e2metros de entrada, sendo eles o array a ser arrumado, o t\u00edtulo da se\u00e7\u00e3o sendo analizada e verbose para impress\u00e3o em tela. Seu funcionamento ocorre ao percorrermos o array passado, observando se seus membros obedecem as regras abaixo: Se eu estou na mesma p\u00e1gina, n\u00e3o posso subir na mesma coluna Se eu estou na mesma p\u00e1gina, n\u00e3o posso subir para a esquerda outras regras se mostram necessarias para casos mais espec\u00edficos, entretanto essas duas j\u00e1 contemplam boa parte dos erros de formata\u00e7\u00e3o encontrados. def sortColunas(colunas,Titulo, verbose = False): from re import search for i in range(len(colunas)): if i == 0 and colunas[i][2][4] != Titulo: print(colunas[i][2][4],\"O titulo da se\u00e7\u00e3o e o das colunas n\u00e3o batem\") if verbose else \"\" break elif i == 0: colunas[i][0] = colunas[i+1][0] antes = colunas[i-1] agora = colunas[i] depois = colunas[i+1] if i+1 < len(colunas)-1 else \"\" # corrigindo a coluna de alguns que passaram if depois != \"\" and antes[0] == depois[0] and antes[0] != agora[0] and antes[1][-1]<agora[1][-2]<depois[1][-2]: print(cores[\"ciano\"]+\"\\nConfundi Coluna: \"+cores[\"reset\"], antes[0],agora[0], depois[0]) if verbose else \"\" agora[0] = antes[0] input() if verbose else \"\" # Corrigindo coluna unica if depois != \"\" and depois[0] == 6 and agora[0] in [1,2,4,10] and not search(r'ANEXO ?([IVXL]+|\\u00daNICO?|.*)', depois[2][4]): print(cores[\"amarelo\"]+\"Achei coluna unica: \"+cores[\"reset\"]) if verbose else \"\" k=0 abaixo = depois while i-k>=0 and not (search(r'DECRETO', colunas[i-k][2][4]) and search(r'DECRETO', colunas[i-k][2][4]).span()[0] == 0) and colunas[i-k][0] in [1,2,4,10] and colunas[i-k][1][-1]<abaixo[1][-2] and abaixo[2][-1] == colunas[i-k][2][-1]: colunas[i-k][0] = 6 abaixo = colunas[i-k] k+=1 colunas[i-k][0] = 6 agora = colunas[i] print(colunas[i-k]) if verbose else \"\" print(colunas[i-k+1]) if verbose else \"\" print(\"parei em \", colunas[i-k], \"\\n\") if verbose else \"\" input() if verbose else \"\" # se em mesma pagina if agora[2][-1] == antes[2][-1]: # se eu estou acima do meu antecessor if agora[1][-2]<antes[1][-1]: # se estou na mesma coluna que meu antecessor if agora[0] == antes[0] : print(cores[\"azul\"] + \"\\nMesma coluna Errado:\" + cores[\"reset\"],agora[0], agora[1][-2], antes[1][-1]) if verbose else \"\" k=1 while i-k >= 0 and agora[1][-2] < colunas[i-k][1][-1] and agora[0] == colunas[i-k][0] and agora[2][-1] == colunas[i-k][2][-1] : k+=1 print(\"Botei antes de\", i-k+1, colunas[i-k][0:2]) if verbose else \"\" aux = colunas.pop(i) colunas.insert(i-k+1, aux) print(colunas[i-k][0:2]) if verbose else \"\" print(colunas[i-k+1][0:2]) if verbose else \"\" print(colunas[i-k+2][0:2]) if verbose else \"\" input() if verbose else \"\" # se estou em uma coluna antes do meu antecessor elif agora[0]<antes[0]: print(\"\\033[2J\\033[H\", end='') if verbose else \"\" for a in range(i): print(colunas[a]) if verbose else \"\" print(cores[\"verde\"] + \"\\ndiferentes coluna Errado:\" + cores[\"reset\"] , agora[0:2], antes[0:2]) if verbose else \"\" k=1 while i-k>=0 and (agora[2][-1] == colunas[i-k][2][-1]): if (agora[0] == colunas[i-k][0] and agora[1][-2] > colunas[i-k][1][-1]) or (colunas[i-k][0] < agora[0]): break k+=1 print(\"Botei antes de\", i-k, colunas[i-k][0:2]) if verbose else \"\" aux = colunas.pop(i) colunas.insert(i-k+1, aux) print(colunas[i-k][0:2]) if verbose else \"\" print(colunas[i-k+1][0:2]) if verbose else \"\" print(colunas[i-k+2][0:2]) if verbose else \"\" input() if verbose else \"\" if verbose: for i in range(len(colunas)): print(colunas[i]) return colunas","title":"sortColunas"},{"location":"Rotinas/minera%C3%A7%C3%A3oDOs/#v4py","text":"","title":"v4.py"},{"location":"Rotinas/minera%C3%A7%C3%A3oDOs/#status_1","text":"Em desenvolvimento","title":"Status"},{"location":"Rotinas/minera%C3%A7%C3%A3oDOs/#funcionamento_1","text":"Essa rotina funciona ao tentar arrumar o texto extra\u00eddo do pdf de maneira gulosa para cada par\u00e1grafo. Sua l\u00f3gica funciona de maneira a para cada par\u00e1grafo( pivot ) olha para frente e busca frases cujo as coordenadas indicam: que sou da mesma coluna que o pivot que sou acima do pivot E com isso identificamos os par\u00e1grafos onde a estra\u00e7\u00e3o foi mal realizada. A identifica\u00e7\u00e3o da coluna acontece ao medirmos se h\u00e1 interse\u00e7\u00e3o entre a ar\u00e9a ocupada na dimens\u00e3o X do pivot com a da frase analizada. Isso funciona devido ao fato da arruma\u00e7\u00e3o em colunas se dar separados por margens, assim toda coluna apresenta intesess\u00e3o entre seus paragrafos em rela\u00e7\u00e3o ao eixo X. O problema apenas se da na forma de que o minerador do pdf retira as informa\u00e7\u00f5es, se prendendo apenas ao tamanho da frase em si em vez de ocupar o tamanho da coluna toda. O desenvolvimento foi interrompido antes da solu\u00e7\u00e3o das seguintes quest\u00f5es: Identifica\u00e7\u00e3o dos limites da coluna: O pivot pode estar na mesma coluna da frase e n\u00e3o ser grande o suficiente para englobar a outra frase, caso dos T\u00edtulo com o ID. N\u00e3o acredito que preciso realizar esse c\u00e1lculo previamente, apenas olhando os casos na hora deve ser suficiente. Abaixo a explica\u00e7\u00e3o de sua rotina. Ela se utiliza das seguintes bibliotecas: import os import tqdm import json import re import pymupdf as pdf Temos dois m\u00e9todos de apoio cujo funcionamento se assemelham, infringeSemiEspaco e infringeEspaco . Ambas testam pra ver se h\u00e1 interse\u00e7\u00e3o, sendo que a primeira parcial, isto \u00e9, se temos pelo menos um v\u00e9rtice de algum deles dentro da \u00e1rea do outro, e a segunda total, ambas os v\u00e9rtices dentro da \u00e1rea do outro. def infringeSemiEspaco(e1, e2,indice = 0): maior = e1 if e1[indice+2] - e1[indice] > e2[indice+2] - e2[indice] else e2 if (maior == e1 and ( maior[indice]<=e2[indice]<=maior[indice+2] or maior[indice]<=e2[indice+2]<=maior[indice+2])) or (maior == e2 and ( maior[indice]<=e1[indice]<=maior[indice+2] or maior[indice]<=e1[indice+2]<=maior[indice+2])): return True else: return False def infringeEspaco(e1, e2,indice = 0): maior = e1 if e1[indice+2] - e1[indice] > e2[indice+2] - e2[indice] else e2 if (maior == e1 and ( maior[indice]<=e2[indice]<=maior[indice+2] and maior[indice]<=e2[indice+2]<=maior[indice+2])) or (maior == e2 and ( maior[indice]<=e1[indice]<=maior[indice+2] and maior[indice]<=e1[indice+2]<=maior[indice+2])): return True else: return False A rotina principal tem funcionamento ideintico \u00e0 v3/pdfReader retirando algumas linhas que s\u00e3o consideradas in\u00fateis, como aquelas de propaganda/c\u00f3digos de formata\u00e7\u00e3o que n\u00e3o carregam nenhuma informa\u00e7\u00e3o sobre os decretos, depois separamos cada par\u00e1grafo por p\u00e1gina e come\u00e7amos a procurar os par\u00e1grafos fora de ordem. Essa procura \u00e9 feita olhando para cada par\u00e1grafo se algu\u00e9m abaixo dele, deveria estar acima dele. Fazemos essa procura por causa da l\u00f3gica de leitura e perda de dimensionalidade trazida pelo leitor de PDF, com isso aqueles par\u00e1grafos que se encontram fora de lugar acabam por se encontrarem em um ponto \u00e0 frente de algum de seus colegas de colunas. def retirar(filepath, verbose = False): import re import pymupdf as pdf limites = [52.441368103027344, 87.45538330078125, 761.1741333007812, 1180.38134765625] nomeDir = \"DOsProcessados/Decretos/\"+filepath.split(\"/\")[-1].split(\".\")[0] if not os.path.isdir(\"DOsProcessados\"): os.mkdir(\"DOsProcessados\") os.mkdir(\"DOsProcessados/Decretos\") os.mkdir(nomeDir) elif not os.path.isdir(nomeDir): os.mkdir(nomeDir) doc = pdf.open(filepath) arq = [] for i in doc: pagina = [] for j in i.get_text(\"blocks\"): pagina.append(j) arq.append(pagina) pattern = r'(\\\\x[01][0-9A-Fa-f]|\\\\ufffd)' ## remover caracteres binarios do documento par = 0 pagina = 0 do = [] paragrafo= \"\" valor = False contador = 0 for page in tqdm.tqdm(arq): acc = [] for lines in range(len(page)): if par < page[lines][-2]: par = page[lines][-2] else: par = page[lines][-2] pagina+=1 if (pagina == 1 and page[lines][-2]<19) or (pagina == 2 and page[lines][-2]<18) or (page[lines][4]==\"\") or (len(page[lines][4])<=2): if re.search(r'Id: [0-9]+', page[lines][4]): print('foi aqui 1') if re.search(r'SEI-080002/002420/2024',page[lines][4]): print(page[lines][4]) continue if \"\".join(page[lines][4].split(\"\\n\")) in [\"FI\",\"Solicite seu or\\u00e7amento: \", \"Decreto Estadual 47.364/2020\", \"OBRIGATORIEDADE DE CONSULTA \\u00c0 IMPRENSA OFI-CIAL NAS CONTRATA\\u00c7\\u00d5ES DE SERVI\\u00c7OS GR\\u00c1FI-COS PELA ADMINISTRA\\u00c7\\u00c3O DIRETA E INDIRETA.\", \"2,00R$\", \"Livrosnovosde\", \"at\\u00e9 9,00\", \"programamaisleitura\", \"maisleitura@ioerj.rj.gov.br\", \"Ler \\u00e9 o maior barato!\", \"programamaisleituramaisleitura@ioerj.rj.gov.br\", \" acesso \\u00e0 leitura.acesso \\u00e0 leitura.\", \"Endere\\u00e7os\"]: if re.search(r'Id: [0-9]+', page[lines][4]): print('foi aqui 2') if re.search(r'SEI-080002/002420/2024',page[lines][4]): print(page[lines][4]) continue if re.search(pattern,page[lines][4].encode(\"unicode_escape\").decode()): if re.search(r'Id: [0-9]+', page[lines][4]): print('foi aqui 3') if re.search(r'SEI-080002/002420/2024',page[lines][4]): print(page[lines][4]) continue if \"O VALOR DA\\nSEGURAN\u00c7A\" in page[lines][4]: fraseSem = \"\" booleanValor = False for frase in page[lines][4].split(\"\\n\"): if frase != \"O VALOR DA\" and not booleanValor: fraseSem += frase + \"\\n\" elif frase == \"O VALOR DA\" or booleanValor: booleanValor = True paragrafo += frase aux = list(page[lines]) aux[4]=fraseSem aux[-1] = pagina if re.search(r'Id: [0-9]+', page[lines][4]): print('foi aqui 4') print(len(acc), lines) acc.append(tuple(aux)) valor = True continue elif valor: if acc == \"O VALOR DASEGURAN\u00c7APUBLICOUNAIMPRENSA,\u00c9OFICIAL\": valor = False paragrafo = \"\" else: paragrafo+=page[lines][4].split(\"\\n\")[0] aux = list(page[lines]) aux[-1] = pagina acc.append(tuple(aux)) else: if re.search(r'SEI-080002/002420/2024',page[lines][4]): print(\"AQUIIIIIIIIIIII\") print(page[lines][4]) print(len(acc),lines) aux = list(page[lines]) aux[-1] = pagina acc.append(tuple(aux)) do.append(acc) for pagina2 in range(len(do)): blocos = [] tamanhoPagina = len(do[pagina2]) paragrafo2 = 0 while paragrafo2 < tamanhoPagina: for depois in range(paragrafo2+1,tamanhoPagina): if(do[pagina2][paragrafo2][3] > do[pagina2][depois][3] and infringeEspaco(do[pagina2][paragrafo2], do[pagina2][depois])): for antes in range(0, paragrafo2): if(do[pagina2][depois][3] < do[pagina2][antes][3] and infringeEspaco(do[pagina2][depois], do[pagina2][antes])): print(\"ACHEI\", pagina2) print(do[pagina2][paragrafo2]) print(do[pagina2][depois]) print(do[pagina2][antes]) print() input() paragrafo2 +=1","title":"Funcionamento"}]}